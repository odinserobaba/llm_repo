# ДЗ 9: Information Extraction из новостных диалогов

## Общая цель

Извлечение важной информации (сущностей: PERSON, ORG, LOC, EVENT, DATE, IMPACT, SOURCE) из неструктурированных диалогов с помощью LLM, сравнение производительности разных моделей.

---

## Выбранный трек: B — Извлечение из новостных диалогов

- **Датасет:** [allenai/WildChat-1M](https://huggingface.co/datasets/allenai/WildChat-1M) — 1M реальных диалогов с ChatGPT (публичный, без gated-доступа). Подвыборка 1K–2K примеров.
- **Модели:** TinyLlama-1.1B (быстрая, full/4-bit), Mistral-7B (4-bit), по желанию — OpenChat/Vicuna.
- **Извлекаемые сущности:** PERSON, ORG, LOC, EVENT, DATE, IMPACT, SOURCE.

---

## Структура файлов

| Файл | Описание |
|------|----------|
| `ie_extraction_hw.ipynb` | Основной ноутбук: загрузка данных, модели, IE, batch, анализ |
| `prompt_cognitive_designer.md` | Системный промпт «когнитивный дизайнер» (опционально) |

---

## Этапы выполнения

### 1. Локальное развертывание

- Развернуть 2–3 модели локально (или в Colab).
- Сравнить **quantized** (4-bit) vs **full precision** по скорости и памяти.
- Для Colab T4: TinyLlama — full или 4-bit, Mistral-7B — только 4-bit.

### 2. Подготовка данных

- Загрузить WildChat-1M (или lmsys-chat-1m при наличии доступа).
- Создать подвыборку 500–1K (CPU) или 1K–2K (GPU). Для demo — 100–200.
- Настроить промпты для извлечения сущностей в JSON.

### 3. Оптимизация для IE

- Реализовать **batch processing** (несколько диалогов за один запрос).
- Оптимизировать inference (vLLM, dynamic batching или простая конкатенация).
- Измерить **throughput** (диалогов/мин, tokens/sec) на подвыборке.

### 4. Анализ производительности

- **Скорость:** tokens/sec, время на диалог.
- **Качество:** precision/recall по сущностям (по возможности — silver labels от spaCy/HF NER).
- **Ресурсы:** RAM, VRAM для каждой модели.

---

## Зависимости

- Модуль 9: `09_module_ie/` — NER (spaCy, Hugging Face), IE (relation/event), storage.
- `transformers`, `accelerate`, `bitsandbytes`, `datasets`, `torch`.

---

## Порядок работы

1. Открыть `ie_extraction_hw.ipynb` в **Google Colab** (Runtime → GPU).
2. Выполнить ячейки по порядку: установка → данные → модели → IE → batch → анализ.
3. Сравнить результаты моделей в конце ноутбука.
4. Опционально: подключить системный промпт «когнитивный дизайнер» для объяснений.

---

## Системный промпт «когнитивный дизайнер»

Описание в `prompt_cognitive_designer.md`. Вставь его в системную роль перед запросом — модель будет генерировать объяснения по схеме «якорь → суть → механика → прорыв», с контрастом ошибки и рабочим кодом. Подходит для демонстрации качества генерации в IE-контексте.
