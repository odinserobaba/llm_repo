# ДЗ 9: Information Extraction из диалогов

```
┌─────────────────────────────────────────────────────────────┐
│  IE из диалогов как шпаргалка из чата: PERSON, ORG, DATE,  │
│  EVENT и др. — всё в JSON для аналитики                     │
├────────────┬────────────┬────────────┬──────────────────────┤
│ Якорь     │ Механика   │ Прорыв     │ Применение           │
│ 3 сек     │ 20 сек     │ ✨ 5 сек   │ 10 сек               │
│ Шпаргалка │ WildChat   │ Парсер JSON│ Графики, таблицы,    │
│ из чата   │ + LLM      │ (скобки)   │ демо-приложение      │
└────────────┴────────────┴────────────┴──────────────────────┘
```

---

## 🎯 Якорь + эмоциональный мостик

**🎯 ЯКОРЬ:** Из чата о новостях вытащить: кто упомянут, где, когда, что произошло. LLM возвращает JSON, мы кладём в таблицу и строим графики.

💡 **Эмпатия:** «Звучит как ручной разбор? Сейчас станет проще, чем поиск по ключевым словам в 1000 сообщений.»

---

## 📖 Термины и понятия

| Термин | Что это | Метафора |
|--------|---------|----------|
| **WildChat-1M** | 1M диалогов с ChatGPT. Фильтр language=ru. | 📚 Библиотека чатов |
| **PERSON, ORG, LOC** | Типы сущностей для извлечения. | 🏷️ Ярлыки для слов |
| **Парсер по скобкам** | Модель дописывает после `}` → берём первый `{}`. | ✂️ Вырезать первый блок |
| **«Output ONLY valid JSON»** | Фраза в промпте — меньше мусора после JSON. | 🚫 Стоп-сигнал |
| **Throughput** | Диалогов/сек. Метрика скорости. | ⏱️ Пропускная способность |
| **Batch** | Несколько текстов за один forward. | 📦 Пакетная обработка |

---

## 📐 Радиальная карта

```
                         ┌──────────────────┐
                         │   ДЗ 9           │ ← ЦЕНТР
                         │   IE из диалогов │
                         └────────┬─────────┘
              ┌───────────────────┼───────────────────┐
              ↓                   ↓                    ↓
       ┌────────────┐     ┌────────────┐     ┌────────────┐
       │ Данные     │     │ IE         │     │ Анализ     │
       │ (2 шт.)    │     │ (3 шт.)    │     │ (2 шт.)    │
       └─────┬──────┘     └─────┬──────┘     └─────┬──────┘
             ↓                   ↓                   ↓
       • WildChat-1M       • Промпт JSON        • matplotlib
       • language=ru       • Парсер скобок      • pandas
                           • TinyLlama/Mistral
```

---

## 🔷 Прогрессивная схема (3 фазы)

#### Фаза 1: Данные
```
┌──────────────┐     ┌──────────────┐
│  WildChat    │ ─→  │  Фильтр ru   │
│  1M диалогов │     │  подвыборка  │
└──────────────┘     └──────────────┘
```

#### Фаза 2: IE
```
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│  Диалог      │ ─→  │  Промпт IE   │ ─→  │  LLM        │
└──────────────┘     │  PERSON, ORG │     └──────┬──────┘
                     │  LOC, EVENT… │            ↓
                     └──────────────┘     ┌──────────────┐
                                          │  JSON        │
                                          │  парсер      │
                                          └──────────────┘
```

#### Фаза 3: Прорыв ← ✨ ВОТ ЗДЕСЬ МАГИЯ!
```
┌──────────────┐
│  Модель      │ дописывает текст после JSON?
└──────┬───────┘
       ↓
✨ Парсер по скобкам: берём первый валидный {} 
   «Output ONLY valid JSON» + подсчёт { } — решает проблему
```

---

## 📊 Таблица контрастов

| Что думают ❌ | Что на самом деле ✅ | Визуальная метафора |
|---------------|---------------------|----------------------|
| «JSON всегда валиден» | Модель дописывает после `}` | `Письмо с припиской` |
| «Нужна тяжёлая модель» | TinyLlama достаточна для демо | `Велосипед vs авто` |
| «Только английский» | Фильтр language=ru, промпт RU | `Локализация` |
| «IE = чёрный ящик» | Графики + таблица + примеры | `Дашборд за 5 минут` |

---

## 💻 Мини-код с комментариями-стрелками

```python
# ← 1. Загрузка WildChat, фильтр ru
ds = load_dataset("allenai/WildChat-1M", split="train")
ds_ru = ds.filter(lambda x: x["language"] == "ru")
# ← 2. Промпт IE → LLM
prompt = "Извлеки PERSON, ORG, LOC... Текст: {text}\nТолько JSON."
# ← 3. Парсер первого JSON (подсчёт скобок)
def extract_first_json(text): ...  # берём первый {}
#        ↑
#        └─── ✨ ВОТ ЗДЕСЬ МАГИЯ: модель дописала текст — не ломаем парсинг
```

---

## ✅ Чек-лист самопроверки

```
✅ Проверь себя за 15 секунд:
▫️ Могу объяснить схему: PERSON, ORG, LOC, EVENT, DATE, IMPACT, SOURCE
▫️ Знаю, зачем парсер по скобкам (модель дописывает после JSON)
▫️ Вижу пайплайн: WildChat → промпт → LLM → парсинг → анализ
▫️ Могу построить график распределения сущностей
▫️ Понимаю оптимизацию: batch, 4-bit, throughput

→ Если 4+ галочки — готов к практике.
```

---

## 🔍 Микро-проверка

**Вопрос:** Почему 0% валидного JSON?  
**Ответ:** Модель дописывает текст после `}`. Парсер по скобкам — берём первый валидный `{}` + «Output ONLY valid JSON» в промпте.

**Вопрос:** Зачем TinyLlama для демо?  
**Ответ:** Быстрая, 2–4 GB VRAM. Mistral качественнее, но дольше. Демо = скорость, полный прогон = качество.

---

## ⚠️ Частые ошибки

| Ошибка | Решение |
|--------|---------|
| 0% валидного JSON — модель дописывает после `}` | Парсер по скобкам: `extract_first_json()`, «Output ONLY valid JSON» |
| Медленный прогон | Batch processing, TinyLlama для демо, 4-bit для Mistral |

---

## ➡️ Что дальше

- **АНАЛИЗ_РЕЗУЛЬТАТОВ.md** — разбор проблем парсинга.
- **Практика:** свой датасет (медицина, юриспруденция) — поменяй схему сущностей.

**≈2 ч** — демо на 50 диалогах | **≈1 день** — полный прогон 500+

---

## 📁 Структура файлов

| Файл | Описание |
|------|----------|
| `ie_extraction_hw.ipynb` | Основной: данные, модели, IE, визуализация |
| `АНАЛИЗ_РЕЗУЛЬТАТОВ.md` | Анализ и решения (парсинг и т.д.) |
| `РЕЗУЛЬТАТЫ_rel2_НАГЛЯДНО.md` | Наглядная сводка rel2 |
| `prompt_cognitive_designer.md` | Системный промпт (опционально) |

---

## Трек B — Новостные диалоги

- **Датасет:** WildChat-1M (language=ru)
- **Модели:** TinyLlama-1.1B, Mistral-7B (4-bit)
- **Сущности:** PERSON, ORG, LOC, EVENT, DATE, IMPACT, SOURCE

---

**Порядок:** Colab GPU → `ie_extraction_hw.ipynb` → установка → данные → IE → анализ.
