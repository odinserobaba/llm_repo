{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph: –°–ª–æ–∂–Ω–∞—è State Machine —Å RAG\n",
        "\n",
        "**–¶–µ–ª—å:** –≥—Ä–∞—Ñ —Å 6 —É–∑–ª–∞–º–∏, –¥–≤—É–º—è —É—Å–ª–æ–≤–Ω—ã–º–∏ —Ä—ë–±—Ä–∞–º–∏ –∏ –¥–≤—É–º—è —Ü–∏–∫–ª–∞–º–∏ ‚Äî –≤–∏–¥–Ω–∞ –ø–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ–±—Ö–æ–¥–∞.\n",
        "\n",
        "**–ì—Ä–∞—Ñ:**\n",
        "```\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ  router_ctx: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π?      ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "START ‚Üí retrieve ‚îÄ‚îÄ‚î¨‚Üí enrich ‚Üí retrieve (—Ü–∏–∫–ª –æ–±–æ–≥–∞—â–µ–Ω–∏—è)\n",
        "                   ‚îî‚Üí generate\n",
        "                         ‚îÇ\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ router_quality: –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π?\n",
        "                    ‚Üì         ‚Üì\n",
        "                 critique   END\n",
        "                    ‚îÇ\n",
        "                  refine ‚Üí generate (—Ü–∏–∫–ª —É–ª—É—á—à–µ–Ω–∏—è)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ –Ø–∫–æ—Ä—å\n",
        "–î–≤–∞ —Ü–∏–∫–ª–∞, –¥–≤–∞ —Ä–æ—É—Ç–µ—Ä–∞: `retrieve‚Üîenrich` (–∫–æ–Ω—Ç–µ–∫—Å—Ç) –∏ `generate‚Üîcritique‚Üîrefine` (–∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞)."
      ],
      "id": "038bb415"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ‚Üê 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ (Colab: Runtime ‚Üí GPU)\n",
        "!pip install -q langgraph langchain langchain-core langchain-community\n",
        "!pip install -q transformers accelerate torch"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "12be89d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ‚ö†Ô∏è **–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ `torchvision::nms does not exist`:** –∏—Å–ø–æ–ª—å–∑—É–π `model.generate()` –Ω–∞–ø—Ä—è–º—É—é –≤–º–µ—Å—Ç–æ pipeline ‚Äî —Å–º. [ie_extraction_hw](09_hw_ie_extraction) –∫–∞–∫ –æ–±–æ–π—Ç–∏ –∏–º–ø–æ—Ä—Ç pipeline."
      ],
      "id": "bab29c4e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ª–æ–π LLM (TinyLlama 1.1B)\n",
        "\n",
        "TinyLlama –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ Colab T4 (~2‚Äì4 GB VRAM). –ë–µ–∑ 4-bit ‚Äî –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –¥–µ–º–æ."
      ],
      "id": "50888bae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # –æ—Ç–∫—Ä—ã—Ç–∞—è, ~2.2 GB\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=128,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "print(\"LLM –∑–∞–≥—Ä—É–∂–µ–Ω–∞, device:\", next(model.parameters()).device)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9a81dfd6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. State –∏ —É–∑–ª—ã –≥—Ä–∞—Ñ–∞\n",
        "\n",
        "### –°–æ—Å—Ç–æ—è–Ω–∏–µ (State)\n",
        "| –ü–æ–ª–µ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |\n",
        "|------|------------|\n",
        "| messages | –î–∏–∞–ª–æ–≥: –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è + –æ—Ç–≤–µ—Ç—ã LLM |\n",
        "| context | –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ ¬´–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤¬ª (RAG) |\n",
        "| enrich_count | –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ —É–∂–µ –æ–±–æ–≥–∞—â–∞–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç |\n",
        "| critique_count | –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∫—Ä–∏—Ç–∏–∫–æ–≤–∞–ª–∏ –æ—Ç–≤–µ—Ç |\n",
        "| feedback | –ó–∞–º–µ—á–∞–Ω–∏–µ –æ—Ç critique –¥–ª—è –¥–æ—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ |\n",
        "\n",
        "### –£–∑–ª—ã ‚Äî —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–∞–∂–¥—ã–π\n",
        "\n",
        "| –£–∑–µ–ª | –ü–æ‚Äë—Ä—É—Å—Å–∫–∏ | –õ–æ–≥–∏–∫–∞ |\n",
        "|------|-----------|--------|\n",
        "| **retrieve** | –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | –ë–µ—Ä—ë—Ç ¬´–¥–æ–∫—É–º–µ–Ω—Ç—ã¬ª –ø–æ –≤–æ–ø—Ä–æ—Å—É. –í –¥–µ–º–æ: –ø–µ—Ä–≤—ã–π —Ä–∞–∑ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –∫—É—Å–æ–∫, –ø–æ—Å–ª–µ enrich ‚Äî –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç. –í —Ä–µ–∞–ª—å–Ω–æ–º RAG –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫. |\n",
        "| **enrich** | –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | ¬´–ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ ‚Äî –Ω–∞–¥–æ –µ—â—ë¬ª. –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á—ë—Ç—á–∏–∫. –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ ‚Äî —Å–Ω–æ–≤–∞ retrieve, –∫–æ—Ç–æ—Ä—ã–π –≤–µ—Ä–Ω—ë—Ç –±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞. |\n",
        "| **generate** | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ | –í—ã–∑—ã–≤–∞–µ—Ç LLM: ¬´–í–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –≤–æ—Ç –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—Ç—å¬ª. –ï—Å–ª–∏ –µ—Å—Ç—å feedback (–ø–æ—Å–ª–µ critique), –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –ø—Ä–æ–º–ø—Ç: ¬´–£—á—Ç–∏ –∑–∞–º–µ—á–∞–Ω–∏–µ: ‚Ä¶¬ª. |\n",
        "| **critique** | –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ | ¬´–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π¬ª. –ü–∏—à–µ—Ç –≤ feedback: ¬´–î–∞–π –±–æ–ª–µ–µ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç¬ª. –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç critique_count. |\n",
        "| **refine** | –î–æ—Ä–∞–±–æ—Ç–∫–∞ | –¢–æ–ª—å–∫–æ –ø–µ—Ä–µ–¥–∞—ë—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ generate. –°–æ—Å—Ç–æ—è–Ω–∏–µ —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ critique (–µ—Å—Ç—å feedback), generate –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –≤—ã–∑–æ–≤–µ. |\n",
        "\n",
        "### –†—ë–±—Ä–∞ ‚Äî –∫—É–¥–∞ –∏–¥—ë–º –∏ –ø–æ—á–µ–º—É\n",
        "\n",
        "| –†–µ–±—Ä–æ | –¢–∏–ø | –£—Å–ª–æ–≤–∏–µ | –ö—É–¥–∞ –≤–µ–¥—ë—Ç |\n",
        "|-------|-----|---------|------------|\n",
        "| **retrieve ‚Üí enrich** | —É—Å–ª–æ–≤–Ω–æ–µ | –ö–æ–Ω—Ç–µ–∫—Å—Ç < 100 —Å–∏–º–≤–æ–ª–æ–≤ –ò enrich_count < 2 | ¬´–ú–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤¬ª ‚Üí enrich, –ø–æ—Ç–æ–º —Å–Ω–æ–≤–∞ retrieve |\n",
        "| **retrieve ‚Üí generate** | —É—Å–ª–æ–≤–Ω–æ–µ | –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ò–õ–ò enrich_count ‚â• 2 | ¬´–•–≤–∞—Ç–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞¬ª ‚Üí —Å—Ä–∞–∑—É –≥–µ–Ω–µ—Ä–∞—Ü–∏—è |\n",
        "| **enrich ‚Üí retrieve** | –∂—ë—Å—Ç–∫–æ–µ | –í—Å–µ–≥–¥–∞ | –û–±–æ–≥–∞—Ç–∏–ª–∏ —Å—á—ë—Ç—á–∏–∫ ‚Üí —Å–Ω–æ–≤–∞ –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ |\n",
        "| **generate ‚Üí critique** | —É—Å–ª–æ–≤–Ω–æ–µ | –û—Ç–≤–µ—Ç < 30 —Å–∏–º–≤–æ–ª–æ–≤ –ò critique_count < 2 | ¬´–û—Ç–≤–µ—Ç —Å–ª–∞–±—ã–π¬ª ‚Üí critique ‚Üí refine ‚Üí generate |\n",
        "| **generate ‚Üí END** | —É—Å–ª–æ–≤–Ω–æ–µ | –û—Ç–≤–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π –ò–õ–ò critique_count ‚â• 2 | ¬´–û—Ç–≤–µ—Ç –æ–∫¬ª ‚Üí –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ |\n",
        "| **critique ‚Üí refine** | –∂—ë—Å—Ç–∫–æ–µ | –í—Å–µ–≥–¥–∞ | –ö—Ä–∏—Ç–∏–∫–∞ –≥–æ—Ç–æ–≤–∞ ‚Üí refine –ø–µ—Ä–µ–¥–∞—ë—Ç –≤ generate |\n",
        "| **refine ‚Üí generate** | –∂—ë—Å—Ç–∫–æ–µ | –í—Å–µ–≥–¥–∞ | –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —É—á—ë—Ç–æ–º feedback |"
      ],
      "id": "fee28c27"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import TypedDict\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# ‚Üê 1. –°–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
        "class State(TypedDict):\n",
        "    messages: list\n",
        "    context: str\n",
        "    enrich_count: int\n",
        "    critique_count: int\n",
        "    feedback: str\n",
        "\n",
        "# –î–µ–º–æ: \"–¥–æ–∫—É–º–µ–Ω—Ç—ã\" –Ω–∞—Ä–∞—â–∏–≤–∞—é—Ç—Å—è –ø—Ä–∏ enrich (—Å–∏–º—É–ª–∏—Ä—É–µ–º –º–Ω–æ–≥–æ—Ä–∞—É–Ω–¥–æ–≤—ã–π retrieve)\n",
        "CHUNK = \"RAG ‚Äî Retrieval-Augmented Generation. –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ + LLM –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.\"\n",
        "FULL_DOCS = CHUNK + \" \" + \"–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–∫–ª–∞–¥—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ø—Ä–æ–º–ø—Ç. LLM –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\"\n",
        "\n",
        "def retrieve(state: State) -> dict:\n",
        "    \"\"\"–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (RAG). –í –¥–µ–º–æ: –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞—Ö–æ–¥–µ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç,\n",
        "    –ø–æ—Å–ª–µ enrich ‚Äî –¥–ª–∏–Ω–Ω–µ–µ. –†–µ–∞–ª—å–Ω–æ –∑–¥–µ—Å—å –±—ã–ª –±—ã retriever.invoke(question).\"\"\"\n",
        "    ec = state.get(\"enrich_count\", 0)\n",
        "    if TRACE:\n",
        "        src = \"START\" if ec == 0 else \"enrich\"\n",
        "        print(f\"\\n  [–£–ó–ï–õ] retrieve ‚Üê –ø–æ —Ä–µ–±—Ä—É {src}‚Üíretrieve\")\n",
        "    ctx = CHUNK if ec == 0 else FULL_DOCS + \" [–¥–æ–ø. —Ä–∞—É–Ω–¥ \" + str(ec) + \"]\"\n",
        "    return {\"context\": ctx}\n",
        "\n",
        "def enrich(state: State) -> dict:\n",
        "    \"\"\"¬´–ú–∞–ª–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞¬ª ‚Äî —Å—Ç–∞–≤–∏–º —Ñ–ª–∞–≥, —á—Ç–æ –Ω—É–∂–Ω–æ –µ—â—ë. –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º enrich_count;\n",
        "    —Å–ª–µ–¥—É—é—â–∏–π —É–∑–µ–ª ‚Äî retrieve, –æ–Ω –≤–µ—Ä–Ω—ë—Ç –±–æ–ª—å—à–µ (–≤ –¥–µ–º–æ ‚Äî –ø–æ —Å—á—ë—Ç—á–∏–∫—É).\"\"\"\n",
        "    ec = state.get(\"enrich_count\", 0) + 1\n",
        "    if TRACE:\n",
        "        print(f\"\\n  [–£–ó–ï–õ] enrich ‚Üê –ø–æ —Ä–µ–±—Ä—É router_ctx(enrich)‚Üíenrich\")\n",
        "    return {\"enrich_count\": ec}\n",
        "\n",
        "def generate(state: State) -> dict:\n",
        "    \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM: –∫–æ–Ω—Ç–µ–∫—Å—Ç + –≤–æ–ø—Ä–æ—Å (+ feedback, –µ—Å–ª–∏ –±—ã–ª critique).\"\"\"\n",
        "    src = \"refine‚Üígenerate\" if state.get(\"feedback\") else \"retrieve‚Üígenerate\"\n",
        "    if TRACE:\n",
        "        print(f\"\\n  [–£–ó–ï–õ] generate ‚Üê –ø–æ —Ä–µ–±—Ä—É {src} (–∂—ë—Å—Ç–∫–æ–µ)\")\n",
        "    question = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "    fb = state.get(\"feedback\", \"\")\n",
        "    extra = f\"\\n–£—á—Ç–∏ –∑–∞–º–µ—á–∞–Ω–∏–µ: {fb}\" if fb else \"\"\n",
        "    prompt = f\"\"\"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {state['context']}\\n–í–æ–ø—Ä–æ—Å: {question}{extra}\\n–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"messages\": state[\"messages\"] + [AIMessage(content=response)], \"feedback\": \"\"}\n",
        "\n",
        "def critique(state: State) -> dict:\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ‚Üí –ø–∏—à–µ–º feedback ¬´–±—É–¥—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–µ–µ¬ª.\"\"\"\n",
        "    if TRACE:\n",
        "        print(f\"\\n  [–£–ó–ï–õ] critique ‚Üê –ø–æ —Ä–µ–±—Ä—É router_quality(critique)‚Üícritique\")\n",
        "    last = state[\"messages\"][-1]\n",
        "    text = last.content if hasattr(last, \"content\") else str(last)\n",
        "    return {\n",
        "        \"feedback\": \"–î–∞–π –±–æ–ª–µ–µ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç, –º–∏–Ω–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\",\n",
        "        \"critique_count\": state.get(\"critique_count\", 0) + 1,\n",
        "    }\n",
        "\n",
        "def refine(state: State) -> dict:\n",
        "    \"\"\"–î–æ—Ä–∞–±–æ—Ç–∫–∞: critique —É–∂–µ –∑–∞–ø–∏—Å–∞–ª feedback –≤ state; –∏–¥—ë–º –≤ generate ‚Äî –æ–Ω –µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç.\"\"\"\n",
        "    if TRACE:\n",
        "        print(f\"\\n  [–£–ó–ï–õ] refine ‚Üê –ø–æ —Ä–µ–±—Ä—É critique‚Üírefine (–∂—ë—Å—Ç–∫–æ–µ)\")\n",
        "    return {}  # generate –≤–æ–∑—å–º—ë—Ç feedback –∏–∑ state\n",
        "\n",
        "# –í–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –æ–±—Ö–æ–¥–∞ –≥—Ä–∞—Ñ–∞ (False = –±–µ–∑ –ª–æ–≥–æ–≤)\n",
        "TRACE = True"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d8889738"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –†–æ—É—Ç–µ—Ä—ã: –∫–∞–∫ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–µ–µ —Ä–µ–±—Ä–æ\n",
        "\n",
        "**router_ctx** ‚Äî —Ä–µ—à–∞–µ—Ç –ø–æ—Å–ª–µ retrieve:\n",
        "- `enrich`: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –º–∞–ª–æ (< 100 —Å–∏–º–≤–æ–ª–æ–≤) –∏ –º—ã –µ—â—ë –Ω–µ –æ–±–æ–≥–∞—â–∞–ª–∏ 2 —Ä–∞–∑–∞ ‚Üí –∏–¥—ë–º –æ–±–æ–≥–∞—â–∞—Ç—å –∏ —Å–Ω–æ–≤–∞ –∏—Å–∫–∞—Ç—å\n",
        "- `generate`: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–ª–∏ –ª–∏–º–∏—Ç –æ–±–æ–≥–∞—â–µ–Ω–∏–π –∏—Å—á–µ—Ä–ø–∞–Ω ‚Üí –∏–¥—ë–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç\n",
        "\n",
        "**router_quality** ‚Äî —Ä–µ—à–∞–µ—Ç –ø–æ—Å–ª–µ generate:\n",
        "- `critique`: –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (< 30 —Å–∏–º–≤–æ–ª–æ–≤) –∏ –º—ã –µ—â—ë –Ω–µ –∫—Ä–∏—Ç–∏–∫–æ–≤–∞–ª–∏ 2 —Ä–∞–∑–∞ ‚Üí –∏–¥—ë–º –≤ critique –¥–ª—è –¥–æ—Ä–∞–±–æ—Ç–∫–∏\n",
        "- `end`: –æ—Ç–≤–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π –∏–ª–∏ –ª–∏–º–∏—Ç –¥–æ—Ä–∞–±–æ—Ç–æ–∫ –∏—Å—á–µ—Ä–ø–∞–Ω ‚Üí –∑–∞–≤–µ—Ä—à–∞–µ–º"
      ],
      "id": "9cdf446c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def router_ctx(state: State) -> str:\n",
        "    \"\"\"–ü–æ—Å–ª–µ retrieve: –º–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤? ‚Üí enrich (–µ—â—ë –ø–æ–∏—â–µ–º). –•–≤–∞—Ç–∞–µ—Ç? ‚Üí generate.\"\"\"\n",
        "    ctx = state.get(\"context\", \"\")\n",
        "    ec = state.get(\"enrich_count\", 0)\n",
        "    short_ctx = len(ctx.strip()) < 100\n",
        "    if short_ctx and ec < 2:\n",
        "        if TRACE:\n",
        "            print(f\"  [–í–ï–¢–í–õ–ï–ù–ò–ï] router_ctx: context={len(ctx)} —Å–∏–º–≤–æ–ª–æ–≤, enrich_count={ec} ‚Üí enrich\")\n",
        "        return \"enrich\"\n",
        "    if TRACE:\n",
        "        print(f\"  [–í–ï–¢–í–õ–ï–ù–ò–ï] router_ctx: context={len(ctx)} —Å–∏–º–≤–æ–ª–æ–≤ ‚Üí generate\")\n",
        "    return \"generate\"\n",
        "\n",
        "def router_quality(state: State) -> str:\n",
        "    \"\"\"–ü–æ—Å–ª–µ generate: –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π? ‚Üí critique (–¥–æ—Ä–∞–±–æ—Ç–∞–µ–º). –ù–æ—Ä–º? ‚Üí end.\"\"\"\n",
        "    last = state[\"messages\"][-1] if state.get(\"messages\") else None\n",
        "    text = (last.content if hasattr(last, \"content\") else str(last)) if last else \"\"\n",
        "    cc = state.get(\"critique_count\", 0)\n",
        "    short = len(text.strip()) < 30\n",
        "    if short and cc < 2:\n",
        "        if TRACE:\n",
        "            print(f\"  [–í–ï–¢–í–õ–ï–ù–ò–ï] router_quality: –æ—Ç–≤–µ—Ç={len(text.strip())} —Å–∏–º–≤–æ–ª–æ–≤, critique_count={cc} ‚Üí critique\")\n",
        "        return \"critique\"\n",
        "    if TRACE:\n",
        "        print(f\"  [–í–ï–¢–í–õ–ï–ù–ò–ï] router_quality: –æ—Ç–≤–µ—Ç={len(text.strip())} —Å–∏–º–≤–æ–ª–æ–≤ ‚Üí end\")\n",
        "    return \"end\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ca56ac84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –°–±–æ—Ä–∫–∞ –≥—Ä–∞—Ñ–∞: —É–∑–ª—ã + —Ä—ë–±—Ä–∞\n",
        "\n",
        "| –†–µ–±—Ä–æ | –ö–æ–¥ | –ü–æ—è—Å–Ω–µ–Ω–∏–µ |\n",
        "|-------|-----|-----------|\n",
        "| retrieve ‚Üí ? | add_conditional_edges(router_ctx) | –ú–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤? ‚Üí enrich. –•–≤–∞—Ç–∞–µ—Ç? ‚Üí generate |\n",
        "| enrich ‚Üí retrieve | add_edge | ¬´–ü–æ–¥—Ç—è–Ω—É–ª–∏ –µ—â—ë¬ª ‚Üí —Å–Ω–æ–≤–∞ –ø–æ–∏—Å–∫ |\n",
        "| generate ‚Üí ? | add_conditional_edges(router_quality) | –°–ª–∞–±—ã–π –æ—Ç–≤–µ—Ç? ‚Üí critique. –ù–æ—Ä–º? ‚Üí END |\n",
        "| critique ‚Üí refine | add_edge | ¬´–ö—Ä–∏—Ç–∏–∫–∞ –≥–æ—Ç–æ–≤–∞¬ª ‚Üí refine |\n",
        "| refine ‚Üí generate | add_edge | ¬´–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å —É—á—ë—Ç–æ–º –∑–∞–º–µ—á–∞–Ω–∏–π¬ª ‚Üí generate |"
      ],
      "id": "90d0026d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# –£–∑–ª—ã\n",
        "workflow.add_node(\"retrieve\", retrieve)   # –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
        "workflow.add_node(\"enrich\", enrich)      # ¬´–º–∞–ª–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –ø–æ–¥—Ç—è–Ω—É—Ç—å –µ—â—ë¬ª\n",
        "workflow.add_node(\"generate\", generate)  # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM\n",
        "workflow.add_node(\"critique\", critique)  # –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π?\n",
        "workflow.add_node(\"refine\", refine)      # –ø–µ—Ä–µ–¥–∞—á–∞ –≤ generate —Å feedback\n",
        "\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "\n",
        "# –£–°–õ–û–í–ù–û–ï: retrieve ‚Üí –º–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤? enrich : generate\n",
        "workflow.add_conditional_edges(\"retrieve\", router_ctx, {\"enrich\": \"enrich\", \"generate\": \"generate\"})\n",
        "\n",
        "# –ñ–Å–°–¢–ö–û–ï: enrich ‚Üí —Å–Ω–æ–≤–∞ retrieve (–ø–æ–¥—Ç—è–Ω–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)\n",
        "workflow.add_edge(\"enrich\", \"retrieve\")\n",
        "\n",
        "# –£–°–õ–û–í–ù–û–ï: generate ‚Üí –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π? critique : END\n",
        "workflow.add_conditional_edges(\"generate\", router_quality, {\"critique\": \"critique\", \"end\": END})\n",
        "\n",
        "# –ñ–Å–°–¢–ö–ò–ï: critique ‚Üí refine ‚Üí generate (–¥–æ—Ä–∞–±–æ—Ç–∫–∞ —Å —É—á—ë—Ç–æ–º –∑–∞–º–µ—á–∞–Ω–∏–π)\n",
        "workflow.add_edge(\"critique\", \"refine\")\n",
        "workflow.add_edge(\"refine\", \"generate\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"–ì—Ä–∞—Ñ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω: 6 —É–∑–ª–æ–≤, 2 —É—Å–ª–æ–≤–Ω—ã—Ö —Ä—ë–±—Ä–∞, 2 —Ü–∏–∫–ª–∞\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "377387a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: –∫–∞–∫ –≥—Ä–∞—Ñ —Ö–æ–¥–∏—Ç –ø–æ —Ä—ë–±—Ä–∞–º\n",
        "\n",
        "–ü—Ä–∏ `invoke()` –±—É–¥–µ—Ç –≤–∏–¥–Ω–æ:\n",
        "- **–£–ó–ï–õ** ‚Äî –≤—Ö–æ–¥ –≤ —É–∑–µ–ª –∏ –ø–æ –∫–∞–∫–æ–º—É —Ä–µ–±—Ä—É –ø—Ä–∏—à–ª–∏\n",
        "- **–í–ï–¢–í–õ–ï–ù–ò–ï** ‚Äî —Ä–µ—à–µ–Ω–∏–µ —Ä–æ—É—Ç–µ—Ä–æ–≤: `router_ctx` (enrich|generate), `router_quality` (critique|end)"
      ],
      "id": "b678c9e7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –ó–∞–ø—É—Å–∫"
      ],
      "id": "2466fa22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=== –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ–±—Ö–æ–¥–∞ –≥—Ä–∞—Ñ–∞ ===\")\n",
        "result = app.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"–ß—Ç–æ —Ç–∞–∫–æ–µ RAG?\")],\n",
        "        \"context\": \"\",\n",
        "        \"enrich_count\": 0,\n",
        "        \"critique_count\": 0,\n",
        "        \"feedback\": \"\",\n",
        "    },\n",
        "    config={\"recursion_limit\": 15},  # –∑–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤\n",
        ")\n",
        "\n",
        "print(\"\\n=== –†–µ–∑—É–ª—å—Ç–∞—Ç ===\")\n",
        "for i, m in enumerate(result[\"messages\"]):\n",
        "    role = \"User\" if isinstance(m, HumanMessage) else \"Assistant\"\n",
        "    print(f\"[{role}] {m.content[:200]}{'...' if len(str(m.content)) > 200 else ''}\")\n",
        "\n",
        "print(\"\\nenrich_count:\", result.get(\"enrich_count\", 0), \"| critique_count:\", result.get(\"critique_count\", 0))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9acc5df0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°—Ö–µ–º–∞ –≥—Ä–∞—Ñ–∞\n",
        "\n",
        "```\n",
        "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "     ‚îÇ  retrieve ‚îÇ  ‚Üê entry\n",
        "     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ add_conditional_edges (router_ctx)\n",
        "     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "     ‚Üì           ‚Üì\n",
        " enrich      generate\n",
        "     ‚îÇ           ‚îÇ\n",
        "     ‚îÇ add_edge  ‚îÇ add_conditional_edges (router_quality)\n",
        "     ‚Üì           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        " retrieve      critique   end ‚Üí END\n",
        " (—Ü–∏–∫–ª)           ‚îÇ\n",
        "                  ‚îÇ add_edge\n",
        "                  ‚Üì\n",
        "               refine\n",
        "                  ‚îÇ add_edge\n",
        "                  ‚Üì\n",
        "               generate\n",
        "              (—Ü–∏–∫–ª)\n",
        "```"
      ],
      "id": "7493c95e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}