{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG evaluation с RAGAS (Colab пример)\n",
    "\n",
    "Этот ноутбук повторяет пример из заметки `01_ragas_eval_example` и позволяет локально в Colab:\n",
    "\n",
    "- создать небольшой датасет для оценки RAG,\n",
    "- настроить RAGAS для трёх метрик:\n",
    "  - `Faithfulness`\n",
    "  - `ContextRelevance`\n",
    "  - `AnswerRelevancy`,\n",
    "- запустить оценку и посмотреть результаты.\n",
    "\n",
    "> ⚠️ **Важно:** ниже пример рассчитан на LLM через OpenAI API. Если хочешь использовать Ollama, смотри комментарий в соответствующей ячейке и поменяй `base_url` / ключ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Установка зависимостей (Colab)\n",
    "!pip install -q ragas openai sentence-transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Датасет для оценки\n",
    "\n",
    "Используем несколько простых примеров \"вопрос → ответ + контекст\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset"
   },
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "dataset = EvaluationDataset(\n",
    "    samples=[\n",
    "        SingleTurnSample(\n",
    "            user_input=\"Какой инструмент используется для миграций базы данных?\",\n",
    "            response=\"Для миграций базы данных используется Alembic.\",\n",
    "            retrieved_contexts=[\n",
    "                \"Alembic используется для управления миграциями базы данных в SQLAlchemy.\",\n",
    "            ],\n",
    "        ),\n",
    "        SingleTurnSample(\n",
    "            user_input=\"Что такое FastAPI?\",\n",
    "            response=\"FastAPI — это современный Python-фреймворк для создания API.\",\n",
    "            retrieved_contexts=[\n",
    "                \"FastAPI — это современный Python-фреймворк для создания API.\",\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "len(dataset.samples), dataset.samples[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Настройка LLM и embedding-модели\n",
    "\n",
    "### Вариант A: OpenAI API (gpt-4o-mini / gpt-4.1 и т.п.)\n",
    "\n",
    "Нужно выставить переменную окружения `OPENAI_API_KEY` (в Colab: `os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"`).\n",
    "\n",
    "### Вариант B: Ollama с OpenAI-совместимым API\n",
    "\n",
    "Если ты запускаешь код локально и используешь Ollama:\n",
    "\n",
    "```python\n",
    "client = AsyncOpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "llm = llm_factory(\"mistral\", client=client)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llm-emb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# === LLM ===\n",
    "# В Colab по умолчанию используем OpenAI API (замени модель при необходимости).\n",
    "# Убедись, что задан OPENAI_API_KEY (через переменные окружения или напрямую в коде).\n",
    "\n",
    "client = AsyncOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"\"))\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "# === Embeddings ===\n",
    "embeddings = HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "llm, embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Метрики: Faithfulness, ContextRelevance, AnswerRelevancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from ragas.metrics.collections import (\n",
    "    Faithfulness,\n",
    "    AnswerRelevancy,\n",
    "    ContextRelevance,\n",
    ")\n",
    "\n",
    "\n",
    "class Result(BaseModel):\n",
    "    faithfulness: float\n",
    "    answer_relevancy: float\n",
    "    context_relevance: float\n",
    "\n",
    "\n",
    "async def evaluate_sample(sample: SingleTurnSample) -> Result:\n",
    "    \"\"\"Оценка одной пары (вопрос, ответ, контекст) по трём метрикам.\"\"\"\n",
    "\n",
    "    # 1. Faithfulness — верность контексту\n",
    "    faith = await Faithfulness(llm=llm).ascore(\n",
    "        user_input=sample.user_input,\n",
    "        response=sample.response,\n",
    "        retrieved_contexts=sample.retrieved_contexts,\n",
    "    )\n",
    "\n",
    "    # 2. AnswerRelevancy — релевантность ответа вопросу\n",
    "    ar = await AnswerRelevancy(\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "    ).ascore(\n",
    "        user_input=sample.user_input,\n",
    "        response=sample.response,\n",
    "    )\n",
    "\n",
    "    # 3. ContextRelevance — релевантность контекста запросу\n",
    "    cr = await ContextRelevance(\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "    ).ascore(\n",
    "        user_input=sample.user_input,\n",
    "        retrieved_contexts=sample.retrieved_contexts,\n",
    "    )\n",
    "\n",
    "    return Result(\n",
    "        faithfulness=faith.value,\n",
    "        answer_relevancy=ar.value,\n",
    "        context_relevance=cr.value,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Запуск оценки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run"
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    tasks = [evaluate_sample(sample) for sample in dataset.samples]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    for i, res in enumerate(results):\n",
        "        print(f\"Sample {i + 1}: {res}\")\n",
    "\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
