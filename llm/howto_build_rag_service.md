## How‑to: собрать RAG‑сервис от нуля до пайплайна

**Цель:** понятный план, как из «есть тексты» прийти к работающему RAG‑сервису.

---

### Когда это использовать

- Хочешь прототип ассистента по своим документам.
- Нужно понять, *какие шаги обязательны*, а что можно отложить.

---

### Шаг 1. Определить задачу и данные

- Что именно должен уметь сервис: Q&A, ассистент по документации, чат‑поддержка?
- Какие источники:
  - файлы / базы → векторный индекс;
  - уже структурированные данные → возможно, проще IE + GraphRAG.

**Полезно посмотреть:**

- [[04_module_rag/README|Модуль 4 — RAG (обзор)]]
- [[10_module_cognitive_systems/01_rag_cognitive/README|Когнитивный RAG: когда нужен reasoning поверх retrieval]]

---

### Шаг 2. Построить базовый RAG‑pipeline

Минимальный набор:

1. Препроцессинг и разбиение на чанки.
2. Индекс (BM25 / векторный / гибридный).
3. Функция `retrieve(query)`.
4. Шаблон промпта с подставленным контекстом.

**Пример:**  
- [[04_module_rag/05_rag_pipeline|Полный RAG pipeline (инфраструктура)]]

Обрати внимание на:

- как готовится индекс;
- как обрабатывается запрос (normalization, expansion);
- как формируется финальный промпт.

---

### Шаг 3. Добавить «когнитивный слой» (reasoning поверх RAG)

Когда простого «retrieve → ответь» мало:

- нужны многошаговые рассуждения;
- требуется планировать цепочку запросов к индексу.

**Пример:**

- [[10_module_cognitive_systems/01_rag_cognitive/01_rag_with_reasoning|RAG + reasoning (multi‑hop, CoT)]]

Идея:

- RAG даёт факты;
- поверх них запускается CoT / multi‑step планирование.

---

### Шаг 4. Подготовить промпты для RAG

Ключевой момент — как именно ты подаёшь контекст в LLM:

- ограничить модель в «галлюцинациях»;
- явно указать, что можно и нельзя делать.

**Примеры промптов:**

- [[06_prompting_guide/05_rag_prompt|RAG‑промпты: формат контекста, инструкции]]
- [[06_prompting_guide/04_prompt_chaining|Prompt chaining для сложных запросов]]
- [[06_prompting_guide/03_chain_of_thought|CoT поверх retrieved контекста]]

---

### Шаг 5. Обернуть в сервис (API)

- Сделать один HTTP‑endpoint: `POST /rag_query`:
  - на вход: `question`, опционально `user_id`, `метаданные`;
  - внутри: `retrieve → format_prompt → LLM → postprocessing`.

**Полезно:**

- [[05_module_prod/04_deployment_miniserver|Мини‑сервер для деплоя (FastAPI/Flask)]]

---

### Шаг 6. Добавить мониторинг и трейсинг

Без наблюдаемости RAG превращается в «чёрный ящик».

Сделай:

- логирование запросов/ответов;
- измерения качества (offline/online);
- трассировку шагов (retrieve, LLM, post‑processing).

**Примеры:**

- [[10_module_cognitive_systems/05_profiling_monitoring/01_traces_profiling|Трейсы и профилирование запросов]]
- [[12_hw_rag_langfuse/rag_news_langfuse|RAG + Langfuse (новости)]]

---

### Шаг 7. Где доучиться / расширить

- [[graph_RAG|Graph: RAG и поиск]]
- [[graph_Prompting|Graph: Промптинг и паттерны]]
- [[graph_Prod_Observability|Graph: Прод, мониторинг, Langfuse]]

---

**Теги:** #howto #rag #retrieval #service #prod

