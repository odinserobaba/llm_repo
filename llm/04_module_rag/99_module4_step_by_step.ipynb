{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Модуль 4 (RAG) — пошаговый учебник «как для детей»\n",
        "\n",
        "**Зачем этот блокнот:** объяснить весь модуль 4 очень простыми словами, шаг за шагом, с короткими примерами.\n",
        "\n",
        "**Как читать:** выполняйте сверху вниз, даже если уже знакомы с темой. Здесь всё разложено «по полочкам»."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Что такое RAG (очень коротко)\n",
        "\n",
        "Представь, что у тебя есть **умный помощник** (LLM), но он **не знает все ваши документы**.\n",
        "\n",
        "**RAG** — это способ **дать модели нужные документы прямо перед ответом**.\n",
        "\n",
        "Простая схема:\n",
        "1. Вопрос пользователя.\n",
        "2. Поиск по базе документов.\n",
        "3. Найденные кусочки текста кладём в промпт.\n",
        "4. LLM отвечает **уже с контекстом**.\n",
        "\n",
        "Именно так мы и работали в модуле 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Подготовка среды (Colab)\n",
        "\n",
        "**Правило №1:** все библиотеки ставим в блокноте.\n",
        "\n",
        "Почему? В Colab версии часто конфликтуют. Мы фиксируем нужные версии, чтобы всё работало стабильно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка библиотек (минимально необходимое)\n",
        "%pip -q install -U \\\n",
        "  langchain \\\n",
        "  langchain-community \\\n",
        "  langchain-openai \\\n",
        "  chromadb \\\n",
        "  rank-bm25 \\\n",
        "  matplotlib \\\n",
        "  sentence-transformers \\\n",
        "  pydantic==2.12.3 \\\n",
        "  requests==2.32.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Если Colab ругается на зависимости\n",
        "\n",
        "Иногда в Colab уже стоят «несовместимые» пакеты. Тогда мы фиксируем версии `opentelemetry`.\n",
        "Это не про логику RAG — это **просто ремонт окружения**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Фиксация opentelemetry при конфликтах\n",
        "%pip -q install -U \\\n",
        "  opentelemetry-api==1.37.0 \\\n",
        "  opentelemetry-sdk==1.37.0 \\\n",
        "  opentelemetry-proto==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-grpc==1.37.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Предобработка данных (очистка)\n",
        "\n",
        "**Очень просто:**\n",
        "- удаляем мусор (пустые строки, «служебные» куски),\n",
        "- выравниваем текст (лишние пробелы),\n",
        "- убираем дубликаты.\n",
        "\n",
        "**Зачем?**\n",
        "Если мусор попадёт в базу, поиск станет хуже.\n",
        "\n",
        "В модуле мы сделали отдельный блокнот про это: `00_data_preprocessing.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Загрузка документов и разбиение на кусочки\n",
        "\n",
        "Текст «целиком» слишком большой. Мы режем его на маленькие куски.\n",
        "\n",
        "**Почему?**\n",
        "LLM не сможет проглотить всю книгу. Но сможет прочитать 3–5 нужных кусочков.\n",
        "\n",
        "В модуле это блокнот: `01_load_split.ipynb`.\n",
        "\n",
        "Ключевые параметры:\n",
        "- `chunk_size` — размер кусочка\n",
        "- `chunk_overlap` — перекрытие, чтобы смысл не терялся на границе"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Эмбеддинги — превращаем текст в числа\n",
        "\n",
        "LLM не ищет напрямую по словам. Мы переводим текст в **вектор чисел**.\n",
        "\n",
        "Если два текста похожи по смыслу — их вектора тоже «рядом».\n",
        "\n",
        "В модуле это: `02_embeddings_retrievers.ipynb`.\n",
        "\n",
        "Мы использовали:\n",
        "- `CacheBackedEmbeddings` — чтобы не пересчитывать одно и то же,\n",
        "- `Chroma` — как векторную базу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Векторная база и хранение на диске\n",
        "\n",
        "**Векторная база** хранит эмбеддинги и умеет быстро искать похожие.\n",
        "\n",
        "Мы использовали **Chroma**, и научились хранить базу **на диске**, чтобы не пересоздавать:\n",
        "\n",
        "```\n",
        "persist_directory = \"./db/chroma_rag\"\n",
        "```\n",
        "\n",
        "Это было в `05_rag_pipeline.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Ретривер — «поисковик» для вашей базы\n",
        "\n",
        "Ретривер — это часть, которая **находит нужные кусочки** текста.\n",
        "\n",
        "Мы строили разные виды ретриверов:\n",
        "- обычный (по смыслу),\n",
        "- гибридный (с BM25),\n",
        "- ParentDocumentRetriever (чтобы сохранять контекст).\n",
        "\n",
        "Подробно — в блокнотах `02`–`04`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Гибридный поиск (BM25 + Вектор)\n",
        "\n",
        "Иногда ключевое слово важнее смысла.\n",
        "Например, слово «ИНН» должно попасть точно.\n",
        "\n",
        "Гибридный поиск соединяет:\n",
        "- **BM25** — точные слова\n",
        "- **Вектор** — смысл\n",
        "\n",
        "Мы делали это в `03_hybrid_search.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ParentDocumentRetriever — большие ответы с контекстом\n",
        "\n",
        "Если вернуть только маленький кусочек, ответ может быть «обрывочным».\n",
        "\n",
        "ParentDocumentRetriever делает так:\n",
        "1. Ищет по маленьким кускам,\n",
        "2. Возвращает **родительский** документ побольше.\n",
        "\n",
        "Это было в `04_parent_retriever.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Полный RAG‑пайплайн (как LLM получает знания)\n",
        "\n",
        "Самая важная часть:\n",
        "\n",
        "1. Пользователь пишет вопрос.\n",
        "2. Ретривер ищет релевантные кусочки.\n",
        "3. Эти кусочки добавляются в промпт.\n",
        "4. LLM отвечает, читая **контекст**.\n",
        "\n",
        "LLM **не ищет сама**, ей «подкладывают» нужные фрагменты.\n",
        "\n",
        "Это основной блокнот: `05_rag_pipeline.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. RAG по Markdown\n",
        "\n",
        "Markdown — это текст с заголовками, списками и кодом.\n",
        "\n",
        "Чтобы всё работало хорошо, мы:\n",
        "- аккуратно чистили Markdown,\n",
        "- сохраняли заголовки в метаданных.\n",
        "\n",
        "Это делалось в `06_rag_from_md.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Реальные .md файлы (с кодом)\n",
        "\n",
        "В реальной жизни в документах есть:\n",
        "- кодовые блоки,\n",
        "- HTML/CSS/XPath,\n",
        "- технические куски.\n",
        "\n",
        "Мы сделали специальный парсер, чтобы **не ломать код**.\n",
        "\n",
        "Это блокнот: `07_rag_real_md.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Домашнее задание (Vector DB) — что мы делали\n",
        "\n",
        "Мы повторили «большое» ДЗ:\n",
        "\n",
        "- выбрали векторную БД,\n",
        "- проиндексировали документы,\n",
        "- сравнили скорость и точность,\n",
        "- посмотрели параметры HNSW,\n",
        "- построили график.\n",
        "\n",
        "Это блокнот: `08_hw_vector_db.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Русский датасет (Lenta / ru_news)\n",
        "\n",
        "Мы сделали русскую версию ДЗ:\n",
        "- загрузка Lenta или ru_news без `datasets`,\n",
        "- локальные эмбеддинги (чтобы не зависеть от API),\n",
        "- фильтрация по метаданным,\n",
        "- итоги и выводы.\n",
        "\n",
        "Это блокнот: `09_hw_vector_db_lenta.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Мини‑чеклист (очень коротко)\n",
        "\n",
        "1. Очистить данные.\n",
        "2. Разбить на кусочки.\n",
        "3. Сделать эмбеддинги.\n",
        "4. Положить в векторную базу.\n",
        "5. Настроить ретривер.\n",
        "6. Добавить контекст в промпт.\n",
        "7. Получить ответ.\n",
        "\n",
        "Если вы это умеете — вы уже сделали RAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Что делать дальше\n",
        "\n",
        "Если хотите углубиться:\n",
        "- увеличить объём данных (10k+ документов),\n",
        "- попробовать другой эмбеддер,\n",
        "- сравнить разные параметры HNSW,\n",
        "- добавить тесты качества.\n",
        "\n",
        "Готов продолжить и сделать модуль 5 так же подробно."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
