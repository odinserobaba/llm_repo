# Модуль 4 — RAG: карта понимания

```
┌─────────────────────────────────────────────────────────────┐
│  RAG как библиотекарь: вопрос → он приносит страницу →       │
│  ты читаешь и отвечаешь                                      │
├────────────┬────────────┬────────────┬──────────────────────┤
│ Якорь     │ Механика   │ Прорыв     │ Применение           │
│ 3 сек     │ 20 сек     │ ✨ 5 сек   │ 10 сек               │
│ Оглавление│ Чанки +    │ LLM читает │ Ответ по своим       │
│ книги     │ эмбеддинги │ подложенное│ документам           │
└────────────┴────────────┴────────────┴──────────────────────┘
```

---

## 🎯 Якорь + эмоциональный мостик

**🎯 ЯКОРЬ:** Ты спрашиваешь библиотекаря. Он приносит нужные страницы. Ты их читаешь и формулируешь ответ. LLM в RAG — та же роль: не ищет сама, а **читает то, что ей подложили**.

💡 **Эмпатия:** «Звучит как магия? Сейчас станет проще, чем найти рецепт в кулинарной книге по оглавлению.»

---

## 📖 Термины и понятия

| Термин | Что это | Метафора |
|--------|---------|----------|
| **RAG** | Поиск документов → контекст в промпт → LLM отвечает по ним. | 📚 Библиотекарь приносит страницы |
| **Чанк** | Кусок текста (500 символов). В контекст не влезет целиком. | 🍞 Ломтик хлеба |
| **chunk_overlap** | Перекрытие соседних чанков. Сохраняет связность. | 🔗 Стыковка ломтиков |
| **Эмбеддинг** | Текст → вектор. Похожие тексты → близкие векторы. | 📍 Координаты на карте |
| **Ретривер** | Вопрос → топ-k чанков. По эмбеддингам или BM25. | 🔍 Поисковик |
| **Chroma** | Векторная БД. Хранение и поиск эмбеддингов. | 📦 Склад с координатами |
| **BM25** | Поиск по ключевым словам. Гибрид с вектором. | 🔑 Индекс ключевых слов |

---

## 📐 Радиальная карта модуля

```
                         ┌──────────────────┐
                         │   RAG            │ ← ЦЕНТР
                         │   (Модуль 4)     │
                         └────────┬─────────┘
              ┌───────────────────┼───────────────────┐
              ↓                   ↓                   ↓
       ┌────────────┐     ┌────────────┐     ┌────────────┐
       │ Данные     │     │ Поиск      │     │ Ответ      │
       │ (3 шага)   │     │ (3 способа)│     │ (1 шаг)    │
       └─────┬──────┘     └─────┬──────┘     └─────┬──────┘
             ↓                  ↓                   ↓
       • Preprocessing   • Эмбеддинги        • Контекст +
       • Чанкинг         • Ретривер         • Промпт →
       • Метаданные      • BM25, Hybrid      • LLM
```

---

## 🔷 Прогрессивная схема (3 фазы)

#### Фаза 1: Подготовка данных
```
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│ Документы    │ ─→  │ Очистка      │ ─→  │ Чанки        │
│ (сырые)      │     │ (preprocess) │     │ (chunk_size) │
└──────────────┘     └──────────────┘     └──────┬───────┘
                                                 ↓
                                         overlap, метаданные
```

#### Фаза 2: Поиск (Ретривер)
```
┌──────────────┐
│   Вопрос     │
└──────┬───────┘
       ↓
┌──────────────┐
│  Ретривер    │  ← ищет по эмбеддингам или BM25
└──────┬───────┘
       ↓
┌──────────────┐
│  Чанки       │  топ-k релевантных
└──────┬───────┘
       ↓
┌──────────────┐
│  Промпт      │  Контекст: {чанки} + Вопрос: {вопрос}
└──────┬───────┘
```

#### Фаза 3: Прорыв ← ✨ ВОТ ЗДЕСЬ МАГИЯ!
```
┌──────────────┐
│  LLM         │  получает контекст В ПРОМПТЕ
└──────┬───────┘
       ↓
✨ LLM НЕ ищет в базе — ретривер УЖЕ подложил страницы
   Как официант приносит блюдо, а не готовит его сам
```

---

## 📊 Таблица контрастов

| Что думают ❌ | Что на самом деле ✅ | Визуальная метафора |
|---------------|---------------------|----------------------|
| «LLM сама ищет в базе» | Ретривер ищет, LLM только читает подложенное | `Официант приносит vs готовит` |
| «Чанки = произвольные куски» | chunk_size + overlap + сохранение контекста | `Ломтики хлеба с перекрытием` |
| «Эмбеддинги = магия» | Текст → вектор → поиск «по смыслу» | `Координаты на карте` |
| «Один ретривер на всё» | BM25 + вектор = гибрид (точность + смысл) | `Ключевые слова + синонимы` |

---

## 💻 Мини-код с комментариями-стрелками

```python
# ← 1. Чанкинг: документ → кусочки
splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
chunks = splitter.split_text(text)
#        ↑
#        └── ✨ ВОТ ЗДЕСЬ МАГИЯ: без чанков в контекст не влезет

# ← 2. Эмбеддинги: текст → векторы
emb = HuggingFaceEmbeddings(model_name="...")
db = Chroma.from_texts(chunks, embedding=emb)
# ← 3. Ретривер: вопрос → чанки
retriever = db.as_retriever(k=3)
docs = retriever.invoke("что про экономику?")
# ← 4. Промпт: контекст + вопрос → ответ
```

---

## ✅ Чек-лист самопроверки

```
✅ Проверь себя за 15 секунд:
▫️ Могу объяснить RAG через метафору «библиотекарь приносит страницы»
▫️ Вижу разницу: ретривер ищет, LLM читает
▫️ Знаю, зачем чанки (в контекст не влезут целиком)
▫️ Понимаю эмбеддинги = координаты текста
▫️ Могу собрать цепочку: вопрос → retriever → промпт → LLM

→ Если 4+ галочки — уверенно владеешь основой.
```

---

## 🔍 Микро-проверка

**Вопрос:** LLM сама ищет в базе документов?  
**Ответ:** Нет. Ретривер ищет и подкладывает чанки в промпт. LLM только читает подложенное — как официант приносит блюдо, а не готовит.

**Вопрос:** Зачем чанки, почему не целиком документ?  
**Ответ:** Контекст LLM ограничен (8K–128K токенов). Длинный документ не влезет. Чанки = порции, которые ретривер выбирает по релевантности.

---

## ⚠️ Частые ошибки

| Ошибка | Решение |
|--------|---------|
| Ответ не по документам — «придумывает» | Уменьши chunk_size или увеличь k ретривера, проверь overlap |
| «Контекст слишком длинный» | Меньше чанков в промпте или больше сжатие (summarize) |

---

## ➡️ Что дальше

- **Модуль 5** — Продакшн: трассировка (LangSmith), кэш.
- **ДЗ 12** — RAG + Langfuse: полный пайплайн с метриками.

**≈1 ч** — блокноты | **≈2 ч** — свой RAG на своих данных

---

## 🎬 Сториборд: жизненный цикл RAG‑запроса

Для наглядности можешь открыть Excalidraw‑диаграмму и посмотреть весь путь запроса:

- `User → Retriever → Chunks → Prompt → LLM → Answer`
- где и как «подкладываются» документы,
- куда встают метрики RAGAS (faithfulness, context relevance, answer relevancy),
- как сравнивать версии пайплайна по метрикам.

Сценарий для рисунка описан здесь:

- [[04_module_rag/rag_query_lifecycle_storyboard|Excalidraw сториборд: жизненный цикл RAG‑запроса]]

Создай файл `rag_query_lifecycle_storyboard.excalidraw` в этой же папке и нарисуй по инструкции — после этого клик по ссылке будет открывать готовую диаграмму.

---

## 📁 Блокноты модуля

| Файл | Якорь | Что делаем |
|------|-------|-------------|
| `00_data_preprocessing.ipynb` | Помыть овощи | Очистка текста |
| `01_load_split.ipynb` | Резать хлеб | Чанкинг |
| `02_embeddings_retrievers.ipynb` | Координаты на карте | Эмбеддинги, база |
| `03_hybrid_search.ipynb` | BM25 + вектор | Гибридный поиск |
| `04_parent_retriever.ipynb` | Малый чанк → родитель | Контекст |
| `05_rag_pipeline.ipynb` | Сэндвич из слоёв | RetrievalQA |

---

**Попробуй:** открой `05_rag_pipeline.ipynb` и собери полный RAG.
