## How‑to: завернуть LLM в API и задеплоить

**Цель:** от ноутбука с моделью к работающему HTTP‑сервису.

---

### Когда это использовать

- Есть модель / RAG‑пайплайн / агент в ноутбуке.
- Нужно дать доступ через HTTP (продукт, интеграция, внутренний сервис).

---

### Шаг 1. Определить интерфейс API

Минимальный вариант:

- `POST /llm_query` или `/rag_query`
- тело запроса:
  ```json
  {
    "question": "строка",
    "context": "...опционально...",
    "user_id": "...опционально..."
  }
  ```
- ответ:
  ```json
  {
    "answer": "строка",
    "meta": {...}
  }
  ```

Важно: **фиксируй контракт** (какие поля всегда есть, какие опциональные).

---

### Шаг 2. Вынести ядро логики в функцию

В ноутбуке:

- сделать чистую функцию `run_model(request_dict) -> response_dict`, где:
  - парсишь вход;
  - вызываешь LLM / RAG / агент;
  - делаешь минимальный post‑processing.

Это ядро потом просто вызывается из веб‑фреймворка.

---

### Шаг 3. Обернуть в мини‑сервер

**Пример:**

- [[05_module_prod/04_deployment_miniserver|Мини‑сервер для деплоя (FastAPI/Flask)]]

Идея:

- FastAPI/Flask создаёт endpoint;
- внутри handler просто вызывает `run_model`.

Обрати внимание на:

- валидацию входа;
- дружелюбные сообщения об ошибках;
- таймауты и лимиты.

---

### Шаг 4. Обработка ошибок и ретраи

Даже локальная модель может падать:

- OOM, перегрев, сетевые ошибки к внешним сервисам (если они есть).

**Примеры паттернов:**

- [[05_module_prod/05_retries_backoff|Retries & backoff]]

Практика:

- ретраи для *идемпотентных* операций (например, запрос к retriever);
- правильные коды ответов (`4xx` для ошибок пользователя, `5xx` для серверных).

---

### Шаг 5. Локальный/облачный деплой

Минимальный путь:

- обернуть сервис в Docker (если нужно);
- задеплоить на:
  - VM (EC2/Hetzner);
  - либо на PaaS (Render/Fly.io/Heroku‑подобные).

Важные моменты:

- ресурсы (RAM/GPU);
- переменные окружения (ключи, пути к моделям);
- health‑check endpoint (`/health`).

---

### Шаг 6. Мониторинг и логирование

Подключи:

- базовое логирование (запрос/ответ, метаданные);
- метрики (кол‑во запросов, латентность, ошибки);
- трейсинг шагов (особенно если внутри RAG/агент).

**Полезно:**

- [[10_module_cognitive_systems/05_profiling_monitoring/01_traces_profiling|Профилирование и трейсы]]
- [[12_hw_rag_langfuse/rag_news_langfuse|RAG + Langfuse (пример интеграции)]]

---

### Связанные хабы

- [[graph_Prod_Observability|Graph: Прод, мониторинг, Langfuse]]
- [[graph_RAG|Graph: RAG и поиск]]
- [[graph_Agents_LangGraph|Graph: Агенты и LangGraph]]

---

**Теги:** #howto #deploy #api #prod #serving

