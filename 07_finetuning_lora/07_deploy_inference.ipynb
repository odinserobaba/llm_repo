{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 7: Деплой и инференс адаптированной модели\n",
    "\n",
    "**Как использовать модель после обучения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# 1. Сохранение адаптера (только дельты! ~10-100 MB)\n",
    "# model.save_pretrained(\"my-lora-adapter\")\n",
    "# tokenizer.save_pretrained(\"my-lora-adapter\")\n",
    "\n",
    "# 2. Загрузка для инференса\n",
    "adapter_path = \"my-lora-adapter\"  # или путь из Colab/Drive\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    adapter_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "print(\"Модель загружена. Для генерации:\")\n",
    "print(\"model.generate(tokenizer(prompt, return_tensors='pt').input_ids.to(model.device))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Объединение с базовой моделью (опционально для продакшена)\n",
    "print(\"\"\"\n",
    "# Merge LoRA weights into base model — один файл вместо base + adapter\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"full-model-merged\")\n",
    "\n",
    "# Теперь можно загружать через AutoModelForCausalLM.from_pretrained(\"full-model-merged\")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
