# Модуль 4 — RAG: подробный разбор

Этот файл — подробная теоретическая и практическая карта модуля 4.  
Он объясняет **зачем** нужен каждый блокнот, **как** работает ключевая техника и **как применять** её в реальных задачах.

---

## 0) `00_data_preprocessing.ipynb`

### Теория
Предобработка нужна, чтобы убрать шум, дубликаты и «служебный» текст до индексации.  
Это повышает качество поиска и снижает стоимость токенов.

### Практика в блокноте
- базовая очистка `.txt`  
- раздельное хранение `raw/` и `clean/`  
- рекомендации по PII и метаданным

---

## 1) `01_load_split.ipynb`

### Теория
**RAG (Retrieval‑Augmented Generation)** — подход, где модель отвечает, опираясь на внешний контент.  
Первый шаг — **загрузка** документов и **чанкинг** (разделение на фрагменты).

**Почему это важно:**  
Модель не может «помнить» все документы. Мы готовим небольшой контекст, который можно быстро найти и подать в LLM.

**Исторически:**  
Чанкинг стал базовой техникой, когда стало понятно: качество RAG сильно зависит от качества разбиения текста.

### Практика в блокноте
Вы загружаете файлы из папки `./data` и нарезаете их через `RecursiveCharacterTextSplitter`.

**Ключевые параметры:**
- `chunk_size` — размер чанка;
- `chunk_overlap` — перекрытие, чтобы не терять смысл на границах.

### Практические рекомендации
- Начинайте с 500/50.  
- Увеличивайте чанк для «плотных» документов (юридические, технические).  
- Слишком мелкие чанки ухудшают качество поиска.

---

## 2) `02_embeddings_retrievers.ipynb`

### Теория
**Эмбеддинги** превращают текст в вектор, по которому можно искать похожие фрагменты.  
**Ретривер** — компонент, который находит релевантные чанки для запроса.

**Кэширование эмбеддингов** экономит деньги и ускоряет повторные эксперименты.

### Практика в блокноте
Вы создаёте:
- `CacheBackedEmbeddings` для кэша;
- `Chroma` как векторное хранилище;
- `retriever` для поиска релевантных чанков.

### Практические рекомендации
- Всегда включайте кэш эмбеддингов.
- Храните `persist_directory`, чтобы не пересоздавать базу.
- Подбирайте `k` под свой домен (обычно 3–5).

---

## 3) `03_hybrid_search.ipynb`

### Теория
**Гибридный поиск** объединяет:
- **BM25** (ключевые слова);
- **векторный поиск** (семантика).

Это дает баланс между точностью и смыслом.

**Исторически:**  
Чистый векторный поиск часто пропускает точные термины, а BM25 не понимает смысл.  
Гибридный подход стал индустриальным стандартом.

### Практика в блокноте
Вы строите:
- `BM25Retriever`;
- `Chroma` ретривер;
- `EnsembleRetriever` с весами.

### Практические рекомендации
- Начните с весов 0.5/0.5 и подбирайте под домен.
- Если важны точные термины — увеличивайте вес BM25.
- Если важен контекст — увеличивайте вес векторного поиска.

---

## 4) `04_parent_retriever.ipynb`

### Теория
**ParentDocumentRetriever** индексирует маленькие чанки, но возвращает большие «родительские» документы.  
Это сохраняет контекст и уменьшает риск обрывочных ответов.

### Практика в блокноте
Вы настраиваете:
- `child_splitter` для поиска;
- `parent_splitter` для контекста;
- отдельное хранилище родительских документов.

### Практические рекомендации
- `child_chunk` 200–400, `parent_chunk` 800–1500 — хороший старт.
- Если ответ слишком короткий — увеличьте `parent_chunk`.
- Следите за размером итогового контекста, чтобы не переполнить лимит модели.

---

## 5) `05_rag_pipeline.ipynb`

### Теория (как работает «полный» RAG)
RAG‑ответ строится в несколько этапов. Важно понимать, **как именно LLM получает информацию**:
1. **Вопрос пользователя** поступает в ретривер.
2. **Ретривер** находит релевантные чанки в векторной базе.
3. Эти чанки собираются в **контекст**.
4. **LLM получает промпт**, в который уже встроен контекст, и формирует ответ.

То есть LLM **не ищет в базе сама** — она получает уже найденные фрагменты и отвечает на их основе.

### Практика в блокноте
Вы собираете рабочий пайплайн:
- **Загрузка документов** → чанкинг  
- **Эмбеддинги** → векторная база (Chroma)  
- **Retriever** → получает топ‑чанки  
- **RetrievalQA chain** → формирует промпт с контекстом и даёт финальный ответ

**Что делает RetrievalQA внутри:**
- берёт вопрос;
- вызывает ретривер;
- вставляет найденные чанки в шаблон;
- отправляет это в LLM;
- возвращает текст ответа.

### Как именно LLM получает контекст
LLM получает **готовую строку** с разделами примерно такого вида:
```
Контекст:
[chunk 1]
[chunk 2]
[chunk 3]

Вопрос: ...
Ответ:
```
То есть «знание» приходит не из самой модели, а из переданного контекста.

### Практические рекомендации
- Если ответ «плывёт», снижайте `temperature` и уменьшайте `k`.  
- Если модель не находит нужный факт — увеличьте `k` или улучшите чанкинг.  
- При коротких документах можно уменьшить `chunk_size` для точности.  
- Всегда логируйте **вопрос → найденные чанки → ответ** для оценки качества.

---

## 6) `06_rag_from_md.ipynb`

### Теория
Markdown‑документы часто содержат заголовки, код и служебные блоки.  
Важно корректно извлечь текст и сохранить структуру.

### Практика в блокноте
- загрузка `.md` из папки  
- лёгкая очистка Markdown  
- RAG по подготовленным текстам

### Практические рекомендации
- для сложных Markdown используйте полноценные парсеры  
- сохраняйте заголовки и путь к файлу в метаданных

---

## 7) `07_rag_real_md.ipynb`

### Теория
Реальные документы (например, с HTML/CSS/XPath) требуют сохранения кодовых блоков.  
Разбиение по `##/###` помогает сохранить целостность примеров.

### Практика в блокноте
- парсинг `.md` по заголовкам  
- сохранение кодовых блоков  
- RAG‑ответы по секциям с метаданными

### Практические рекомендации
- не удаляйте кодовые блоки  
- храните метаданные `source/section`

---

## 8) `08_hw_vector_db.ipynb`

### Теория
Полное решение ДЗ: индексация, ANN‑алгоритмы, поиск, trade‑offs.  
Отдельное внимание — HNSW и параметрам `M`, `ef`.

### Практика в блокноте
- AG News (CSV) без `datasets/pandas`  
- базовый поиск, фильтры, метрики  
- сравнение exact vs ANN  
- график скорость vs точность  
- hybrid search и batch‑запросы

---

## 9) `09_hw_vector_db_lenta.ipynb`

### Теория
Русскоязычная версия ДЗ: те же шаги, но на новостях (ru_news / Lenta.ru).

### Практика в блокноте
- переключение датасета (`ru_news` / `lenta`)  
- локальные эмбеддинги (HF) или OpenAI  
- индексация, фильтры, метрики, график  
- автоматические выводы по метрикам

---

## Как использовать модуль 4

1. `01_load_split.ipynb` — подготовка документов.  
2. `02_embeddings_retrievers.ipynb` — векторный поиск.  
3. `03_hybrid_search.ipynb` — гибридный подход.  
4. `04_parent_retriever.ipynb` — сохранение контекста.  
5. `05_rag_pipeline.ipynb` — полный рабочий RAG.  
6. `06_rag_from_md.ipynb` — RAG по Markdown.  
7. `07_rag_real_md.ipynb` — реальные `.md` с кодовыми блоками.  
8. `08_hw_vector_db.ipynb` — решение ДЗ (EN датасет).  
9. `09_hw_vector_db_lenta.ipynb` — решение ДЗ (RU датасет).

---

## Итог модуля 4

К концу модуля вы:
- умеете готовить документы для RAG;
- строите эмбеддинги и ретриверы;
- комбинируете BM25 и векторный поиск;
- сохраняете контекст через ParentDocumentRetriever;
- собираете полный RAG‑пайплайн и понимаете, как LLM получает контекст.
- умеете обрабатывать Markdown и реальные файлы;
- выполняете ДЗ на англ. и русских датасетах.