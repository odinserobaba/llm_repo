{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb394be",
   "metadata": {},
   "source": [
    "# Модуль 4.7 — RAG по реальным Markdown (real_rag_folder)\n",
    "\n",
    "**Цель:** показать, как лучше парсить реальные `.md` файлы с кодовыми блоками и примерами селекторов.\n",
    "\n",
    "**Что сделаем:**\n",
    "- разберём структуру и цели предобработки\n",
    "- распарсим Markdown по заголовкам (без потери кода)\n",
    "- соберём документы с метаданными\n",
    "- построим RAG и зададим вопрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de83a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U \\\n",
    "  langchain \\\n",
    "  langchain-community \\\n",
    "  langchain-openai \\\n",
    "  chromadb \\\n",
    "  pydantic==2.12.3 \\\n",
    "  requests==2.32.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716b2b1",
   "metadata": {},
   "source": [
    "## Если Colab ругается на зависимости\n",
    "\n",
    "Иногда в Colab установлены библиотеки с жёсткими версиями (например, `google-adk` и `opentelemetry`).\n",
    "Если после установки появляются конфликты — зафиксируйте совместимые версии ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1597602",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U \\\n",
    "  opentelemetry-api==1.37.0 \\\n",
    "  opentelemetry-sdk==1.37.0 \\\n",
    "  opentelemetry-proto==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-grpc==1.37.0\n",
    "\n",
    "# На случай, если в окружении уже стоит более новая версия\n",
    "def _force_pins():\n",
    "    import sys, subprocess\n",
    "    pkgs = [\n",
    "        \"opentelemetry-api==1.37.0\",\n",
    "        \"opentelemetry-sdk==1.37.0\",\n",
    "        \"opentelemetry-proto==1.37.0\",\n",
    "        \"opentelemetry-exporter-otlp-proto-common==1.37.0\",\n",
    "        \"opentelemetry-exporter-otlp-proto-grpc==1.37.0\",\n",
    "    ]\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-U\", \"--force-reinstall\"] + pkgs)\n",
    "\n",
    "_force_pins()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ea85b",
   "metadata": {},
   "source": [
    "## Настройка ключа и base URL\n",
    "\n",
    "Для AITunnel укажите `OPENAI_API_KEY` и `OPENAI_BASE_URL`. В Colab лучше хранить ключ в переменной окружения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Введите OPENAI_API_KEY: \")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_BASE_URL\"):\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.aitunnel.ru/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba8378",
   "metadata": {},
   "source": [
    "## Почему здесь нужен особый парсинг\n",
    "\n",
    "В ваших файлах много:\n",
    "- больших кодовых блоков (`html`, `css`, `xpath`)\n",
    "- повторяющейся структуры «пример → HTML → селекторы»\n",
    "- заголовков `##` / `###`, которые лучше использовать как границы чанков\n",
    "\n",
    "Поэтому мы:\n",
    "1) **Не удаляем кодовые блоки** (они несут ключевые ответы)\n",
    "2) **Режем по заголовкам**, а не по длине\n",
    "3) **Сохраняем метаданные** (файл, название примера)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aae83",
   "metadata": {},
   "source": [
    "## Парсинг Markdown по заголовкам\n",
    "\n",
    "Мы разбиваем текст на секции по `##` / `###` и превращаем каждую секцию в отдельный документ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "SOURCE_DIR = Path(\"./real_rag_folder\")\n",
    "\n",
    "heading_re = re.compile(r\"^(###+)\\s+(.*)\")\n",
    "\n",
    "\n",
    "def split_by_headings(text: str):\n",
    "    sections = []\n",
    "    current_title = \"Без заголовка\"\n",
    "    current_lines = []\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        m = heading_re.match(line.strip())\n",
    "        if m:\n",
    "            # сохраняем предыдущую секцию\n",
    "            if current_lines:\n",
    "                sections.append((current_title, \"\\n\".join(current_lines).strip()))\n",
    "            current_title = m.group(2).strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            current_lines.append(line)\n",
    "\n",
    "    if current_lines:\n",
    "        sections.append((current_title, \"\\n\".join(current_lines).strip()))\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    # Сохраняем кодовые блоки, но убираем лишние пробелы вокруг\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "all_docs = []\n",
    "for md_path in sorted(SOURCE_DIR.glob(\"*.md\")):\n",
    "    raw = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    for title, content in split_by_headings(raw):\n",
    "        content = normalize_text(content)\n",
    "        if len(content) < 50:\n",
    "            continue\n",
    "        all_docs.append(\n",
    "            Document(\n",
    "                page_content=f\"### {title}\\n\\n{content}\",\n",
    "                metadata={\n",
    "                    \"source\": md_path.name,\n",
    "                    \"section\": title,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"Секций найдено:\", len(all_docs))\n",
    "print(\"Пример секции:\\n\", all_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8eee9",
   "metadata": {},
   "source": [
    "## RAG по реальным секциям\n",
    "\n",
    "Строим векторную базу и задаём вопрос по селекторам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "store = LocalFileStore(\"./cache/embeddings\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", base_url=os.environ.get(\"OPENAI_BASE_URL\"))\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(embeddings, store, namespace=\"openai\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding=cached_embedder,\n",
    "    persist_directory=\"./db/chroma_real_md\",\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5.2-chat\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=256,\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "class SelectorResult(BaseModel):\n",
    "    selector_type: str = Field(description=\"Тип селектора: css | xpath | playwright | bs4\")\n",
    "    selectors: list[str] = Field(description=\"Список подходящих селекторов\")\n",
    "    explanation: str = Field(description=\"Короткое объяснение выбора\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SelectorResult)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Ты эксперт по селекторам. Используй КОНТЕКСТ ниже.\\n\"\n",
    "        \"Верни ответ СТРОГО в JSON по инструкции.\\n\"\n",
    "        \"{format_instructions}\\n\\n\"\n",
    "        \"КОНТЕКСТ:\\n{context}\\n\\n\"\n",
    "        \"HTML:\\n{html}\\n\\n\"\n",
    "        \"Вопрос: {question}\"\n",
    "    ),\n",
    "    input_variables=[\"context\", \"html\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Пример HTML\n",
    "html_snippet = \"\"\"\n",
    "<nav id=\"main-nav\" class=\"navigation primary\">\n",
    "  <ul class=\"menu\">\n",
    "    <li class=\"menu-item active\"><a href=\"/\">Главная</a></li>\n",
    "    <li class=\"menu-item\"><a href=\"/about\" data-section=\"info\">О нас</a></li>\n",
    "  </ul>\n",
    "</nav>\n",
    "\"\"\".strip()\n",
    "\n",
    "question = \"Подбери селектор для активного пункта меню.\"\n",
    "\n",
    "retrieved = retriever.get_relevant_documents(question)\n",
    "context = \"\\n\\n\".join([d.page_content for d in retrieved])\n",
    "\n",
    "filled = prompt.format(context=context, html=html_snippet, question=question)\n",
    "raw = llm.invoke(filled)\n",
    "\n",
    "# Парсинг в структурированный JSON\n",
    "result = parser.parse(raw.content)\n",
    "print(result.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e71737",
   "metadata": {},
   "source": [
    "## Практические рекомендации\n",
    "\n",
    "- Не удаляйте кодовые блоки — в них главная ценность для RAG.\n",
    "- Режьте по заголовкам `##`/`###`, это соответствует структуре примеров.\n",
    "- Добавляйте метаданные (файл, пример, тема) — это помогает фильтрации.\n",
    "- Для крупных файлов можно разбивать ещё по подзаголовкам внутри примера."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
