{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3091af99",
   "metadata": {},
   "source": [
    "# –ú–æ–¥—É–ª—å 4.5 ‚Äî –ü–æ–ª–Ω—ã–π RAG‚Äë–ø–∞–π–ø–ª–∞–π–Ω\n",
    "\n",
    "**–¶–µ–ª—å:** —Å–æ–±—Ä–∞—Ç—å —Ä–∞–±–æ—á–∏–π RAG: –∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ ‚Üí —Ä–µ—Ç—Ä–∏–≤–µ—Ä ‚Üí –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.\n",
    "\n",
    "**–ß—Ç–æ —Å–¥–µ–ª–∞–µ–º:**\n",
    "- —É—Å—Ç–∞–Ω–æ–≤–∏–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "- –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
    "- –ø–æ—Å—Ç—Ä–æ–∏–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "- —Å–¥–µ–ª–∞–µ–º retrieval‚Äëchain –∏ –ø–æ–ª—É—á–∏–º –æ—Ç–≤–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9960fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U \\\n",
    "  langchain \\\n",
    "  langchain-community \\\n",
    "  langchain-openai \\\n",
    "  chromadb \\\n",
    "  pydantic==2.12.3 \\\n",
    "  requests==2.32.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4849b50",
   "metadata": {},
   "source": [
    "## –ï—Å–ª–∏ Colab —Ä—É–≥–∞–µ—Ç—Å—è –Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "–ò–Ω–æ–≥–¥–∞ –≤ Colab —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Å –∂—ë—Å—Ç–∫–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `google-adk` –∏ `opentelemetry`).\n",
    "–ï—Å–ª–∏ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã ‚Äî –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –≤–µ—Ä—Å–∏–∏ –Ω–∏–∂–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U \\\n",
    "  opentelemetry-api==1.37.0 \\\n",
    "  opentelemetry-sdk==1.37.0 \\\n",
    "  opentelemetry-proto==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
    "  opentelemetry-exporter-otlp-proto-grpc==1.37.0\n",
    "\n",
    "# –ù–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ —É–∂–µ —Å—Ç–æ–∏—Ç –±–æ–ª–µ–µ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è\n",
    "def _force_pins():\n",
    "    import sys, subprocess\n",
    "    pkgs = [\n",
    "        \"opentelemetry-api==1.37.0\",\n",
    "        \"opentelemetry-sdk==1.37.0\",\n",
    "        \"opentelemetry-proto==1.37.0\",\n",
    "        \"opentelemetry-exporter-otlp-proto-common==1.37.0\",\n",
    "        \"opentelemetry-exporter-otlp-proto-grpc==1.37.0\",\n",
    "    ]\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-U\", \"--force-reinstall\"] + pkgs)\n",
    "\n",
    "_force_pins()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e932d",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–∫–∏ `data`\n",
    "\n",
    "–ï—Å–ª–∏ –ø–∞–ø–∫–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–¥–∏–º –µ—ë –∏ –ø–æ–ª–æ–∂–∏–º –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞, —á—Ç–æ–±—ã –≤—Å—ë –∑–∞–ø—É—Å–∫–∞–ª–æ—Å—å —Å—Ä–∞–∑—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fab062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"./data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sample_path = data_dir / \"sample.txt\"\n",
    "if not sample_path.exists():\n",
    "    sample_path.write_text(\n",
    "        \"LangChain ‚Äî —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–±–æ—Ä–∫–∏ LLM‚Äë–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.\\n\"\n",
    "        \"RAG (Retrieval‚ÄëAugmented Generation) —É–ª—É—á—à–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã, –¥–æ–±–∞–≤–ª—è—è –∑–Ω–∞–Ω–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\\n\"\n",
    "        \"–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.\\n\"\n",
    "        \"–ß–∞–Ω–∫–∏–Ω–≥ –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å —Å–º—ã—Å–ª –∏ –Ω–µ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç.\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "print(\"–§–∞–π–ª—ã –≤ data:\", [p.name for p in data_dir.glob(\"*.txt\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867e8e3",
   "metadata": {},
   "source": [
    "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª—é—á–∞ –∏ base URL\n",
    "\n",
    "–î–ª—è AITunnel —É–∫–∞–∂–∏—Ç–µ `OPENAI_API_KEY` –∏ `OPENAI_BASE_URL`. –í Colab –ª—É—á—à–µ —Ö—Ä–∞–Ω–∏—Ç—å –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è.\n",
    "\n",
    "> –ü–æ–¥—Å–∫–∞–∑–∫–∞: –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –∫–ª—é—á –æ–¥–∏–Ω —Ä–∞–∑ –≤ —Ä–∞–∑–¥–µ–ª–µ **Secrets** (–∑–Ω–∞—á–æ–∫ üîë —Å–ª–µ–≤–∞ –≤ Colab), —Ç–æ–≥–¥–∞ –æ–Ω –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –≤–æ –≤—Å–µ—Ö —è—á–µ–π–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eadf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"–í–≤–µ–¥–∏—Ç–µ OPENAI_API_KEY: \")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_BASE_URL\"):\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.aitunnel.ru/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d6eed",
   "metadata": {},
   "source": [
    "## –°–±–æ—Ä–∫–∞ RAG‚Äë–ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "\n",
    "–ú—ã:\n",
    "1) –∑–∞–≥—Ä—É–∑–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
    "2) –Ω–∞—Ä–µ–∂–µ–º –Ω–∞ —á–∞–Ω–∫–∏\n",
    "3) —Å–æ–∑–¥–∞–¥–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É\n",
    "4) –ø–æ—Å—Ç—Ä–æ–∏–º retrieval‚Äëchain, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –æ—Ç–≤–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaa29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "# 1) –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "loader = DirectoryLoader(\"./data\", glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "# 2) –ß–∞–Ω–∫–∏–Ω–≥\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "# 3) –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ + –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ (—Å —Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–∞ –¥–∏—Å–∫–µ)\n",
    "store = LocalFileStore(\"./cache/embeddings\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", base_url=os.environ.get(\"OPENAI_BASE_URL\"))\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(embeddings, store, namespace=\"openai\")\n",
    "\n",
    "persist_dir = Path(\"./db/chroma_rag\")\n",
    "if persist_dir.exists() and any(persist_dir.iterdir()):\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É —Å –¥–∏—Å–∫–∞\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=str(persist_dir),\n",
    "        embedding_function=cached_embedder,\n",
    "    )\n",
    "else:\n",
    "    # –°–æ–∑–¥–∞—ë–º –±–∞–∑—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=cached_embedder,\n",
    "        persist_directory=str(persist_dir),\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 4) Retrieval‚ÄëQA chain\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5.2-chat\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=256,\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    ")\n",
    "\n",
    "question = \"–ß—Ç–æ —Ç–∞–∫–æ–µ RAG –∏ –∑–∞—á–µ–º –æ–Ω –Ω—É–∂–µ–Ω?\"\n",
    "answer = rag_chain.invoke({\"query\": question})\n",
    "print(\"–û—Ç–≤–µ—Ç:\\n\", answer[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7116fc",
   "metadata": {},
   "source": [
    "## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "\n",
    "- –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç—ã ¬´–ø–ª—ã–≤—É—Ç¬ª, —Å–Ω–∏–∂–∞–π—Ç–µ `temperature` –∏ —É–º–µ–Ω—å—à–∞–π—Ç–µ `k`.\n",
    "- –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ `chunk_size`.\n",
    "- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ `persist_directory`, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å –±–∞–∑—É.\n",
    "- –î–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∫–ª—é—á–∞–π—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
