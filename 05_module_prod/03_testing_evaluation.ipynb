{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Модуль 5.3 — Тестирование и оценка качества\n",
        "\n",
        "**Цель:** проверять, что ответы LLM стабильно соответствуют ожиданиям.\n",
        "\n",
        "**Что сделаем:**\n",
        "- напишем мини‑тесты на цепочку\n",
        "- проверим «золотой набор»\n",
        "- посчитаем простую метрику качества"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip -q install -U \\\n",
        "  langchain \\\n",
        "  langchain-community \\\n",
        "  pydantic==2.12.3 \\\n",
        "  requests==2.32.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Мини‑тест на цепочку (без реального API)\n",
        "\n",
        "Используем FakeListLLM — он возвращает заранее заданные ответы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import FakeListLLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "fake = FakeListLLM(responses=[\"Кэш — это память для быстрых повторов.\"])\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Объясни, что такое кэш одним предложением.\")\n",
        "chain = prompt | fake | StrOutputParser()\n",
        "\n",
        "result = chain.invoke({})\n",
        "assert \"Кэш\" in result\n",
        "print(\"Тест пройден:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) «Золотой набор» (golden set)\n",
        "\n",
        "Мини‑таблица вопросов и ожидаемых ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "golden = [\n",
        "    (\"Что такое кэш?\", \"память\"),\n",
        "    (\"Что такое ретривер?\", \"поиск\"),\n",
        "    (\"Что такое RAG?\", \"контекст\"),\n",
        "]\n",
        "\n",
        "# В тестах мы не зовем реальную модель — используем заглушку\n",
        "fake = FakeListLLM(responses=[\n",
        "    \"Кэш — это память для быстрых повторов.\",\n",
        "    \"Ретривер — это поиск по базе.\",\n",
        "    \"RAG — это ответы с контекстом.\",\n",
        "])\n",
        "\n",
        "test_prompt = PromptTemplate.from_template(\"{q}\")\n",
        "chain = test_prompt | fake | StrOutputParser()\n",
        "\n",
        "hits = 0\n",
        "for q, expected_keyword in golden:\n",
        "    ans = chain.invoke({\"q\": q})\n",
        "    ok = expected_keyword in ans.lower()\n",
        "    hits += 1 if ok else 0\n",
        "    print(q, \"->\", ans, \"| ok:\", ok)\n",
        "\n",
        "accuracy = hits / len(golden)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Мини‑регрессия\n",
        "\n",
        "Если упадёт хоть один тест — значит, что-то изменилось в логике."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert accuracy >= 0.66, \"Слишком низкое качество: проверь цепочку\"\n",
        "print(\"Регрессия пройдена\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
