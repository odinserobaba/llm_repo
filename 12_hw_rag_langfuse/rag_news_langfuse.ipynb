{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –î–ó 12: RAG-—Å–∏—Å—Ç–µ–º–∞ + Langfuse\n",
        "\n",
        "**–¶–µ–ª—å:** RAG –Ω–∞ –Ω–æ–≤–æ—Å—Ç–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π Langfuse.\n",
        "\n",
        "**–≠—Ç–∞–ø—ã:**\n",
        "1. RAG-—Å–∏—Å—Ç–µ–º–∞ ‚Äî –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º\n",
        "2. Langfuse ‚Äî Traces, Spans, Generations, Events, Scores\n",
        "3. Datasets + Experiment —Å evaluator\n",
        "4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "> –î–∞—Ç–∞—Å–µ—Ç: Lenta.ru / ru_news. –ú–æ–¥–µ–ª—å: gpt-4o-mini (AITunnel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### üéØ –Ø–∫–æ—Ä—å\n",
        "RAG = –≤–æ–ø—Ä–æ—Å ‚Üí retrieval ‚Üí –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø—Ä–æ–º–ø—Ç–µ ‚Üí –æ—Ç–≤–µ—Ç. Langfuse = –ø—Ä–∏–±–æ—Ä–Ω–∞—è –ø–∞–Ω–µ–ª—å: trace, spans, generations.\n",
        "\n",
        "**–¢–µ—Ä–º–∏–Ω—ã:** RAG | Langfuse | CallbackHandler | Datasets | Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip -q install -U \\\n",
        "  langchain langchain-classic langchain-community langchain-openai \\\n",
        "  chromadb sentence-transformers \\\n",
        "  langfuse \\\n",
        "  python-dotenv requests pydantic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –î–ª—è ru_news ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n",
        "%pip -q install -U huggingface_hub zstandard jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# AITunnel (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"sk-aitunnel-yJoIOQPK7e25oGDMshpYQuK95p9LBEpP\"\n",
        "if not os.environ.get(\"OPENAI_BASE_URL\"):\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.aitunnel.ru/v1/\"\n",
        "\n",
        "# Langfuse (–ø–æ–ª—É—á–∏—Ç—å –Ω–∞ cloud.langfuse.com)\n",
        "if not os.environ.get(\"LANGFUSE_SECRET_KEY\"):\n",
        "    os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-a4454dd1-4216-4581-a5e2-50ee235a500a\"\n",
        "if not os.environ.get(\"LANGFUSE_PUBLIC_KEY\"):\n",
        "    os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-47e2ffa6-422b-4a19-9871-6b10af2fb385\"\n",
        "if not os.environ.get(\"LANGFUSE_BASE_URL\"):\n",
        "    os.environ[\"LANGFUSE_BASE_URL\"] = \"https://cloud.langfuse.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import csv\n",
        "import io\n",
        "import gzip\n",
        "import json\n",
        "import requests\n",
        "\n",
        "N_DOCS = 1500\n",
        "DATASET_MODE = \"ru_news\"  # ru_news | lenta\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "def fill_from_rows(rows):\n",
        "    for row in rows:\n",
        "        title = (row.get(\"title\") or \"\").strip()\n",
        "        body = (row.get(\"text\") or \"\").strip()\n",
        "        topic = (row.get(\"topic\") or \"unknown\").strip()\n",
        "        if not body:\n",
        "            continue\n",
        "        texts.append(f\"{title}. {body}\" if title else body)\n",
        "        labels.append(topic)\n",
        "        if len(texts) >= N_DOCS:\n",
        "            break\n",
        "\n",
        "\n",
        "def fill_from_ru_news(lines):\n",
        "    for line in lines:\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            title = (obj.get(\"title\") or \"\").strip()\n",
        "            body = (obj.get(\"text\") or \"\").strip()\n",
        "            source = (obj.get(\"source\") or \"unknown\").strip()\n",
        "            if not body:\n",
        "                continue\n",
        "            texts.append(f\"{title}. {body}\" if title else body)\n",
        "            labels.append(source)\n",
        "            if len(texts) >= N_DOCS:\n",
        "                break\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "\n",
        "if DATASET_MODE == \"ru_news\":\n",
        "    import zstandard as zstd\n",
        "    from huggingface_hub import HfApi, hf_hub_download\n",
        "\n",
        "    api = HfApi()\n",
        "    files = api.list_repo_files(repo_id=\"IlyaGusev/ru_news\", repo_type=\"dataset\")\n",
        "    data_file = next((f for f in files if f.endswith(\".jsonl.zst\")), None) or next((f for f in files if f.endswith(\".jsonl\")), None)\n",
        "    if not data_file:\n",
        "        raise RuntimeError(\"ru_news: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
        "\n",
        "    path = hf_hub_download(repo_id=\"IlyaGusev/ru_news\", repo_type=\"dataset\", filename=data_file)\n",
        "\n",
        "    if data_file.endswith(\".zst\"):\n",
        "        with open(path, \"rb\") as fh:\n",
        "            dctx = zstd.ZstdDecompressor()\n",
        "            with dctx.stream_reader(fh) as reader:\n",
        "                fill_from_ru_news(io.TextIOWrapper(reader, encoding=\"utf-8\"))\n",
        "    else:\n",
        "        with open(path, encoding=\"utf-8\") as f:\n",
        "            fill_from_ru_news(f)\n",
        "\n",
        "    source_name = \"ru_news\"\n",
        "else:\n",
        "    Path(\"./data\").mkdir(parents=True, exist_ok=True)\n",
        "    urls = [\n",
        "        \"https://raw.githubusercontent.com/yutkin/Lenta.Ru-News-Dataset/master/lenta-ru-news.csv\",\n",
        "        \"https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.gz\",\n",
        "    ]\n",
        "    local_csv = Path(\"./data/lenta-ru-news.csv\")\n",
        "    local_gz = Path(\"./data/lenta-ru-news.csv.gz\")\n",
        "\n",
        "    if local_csv.exists():\n",
        "        r = csv.DictReader(local_csv.open(encoding=\"utf-8\", errors=\"ignore\"))\n",
        "        fill_from_rows(r)\n",
        "    elif local_gz.exists():\n",
        "        with gzip.open(local_gz, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            fill_from_rows(csv.DictReader(f))\n",
        "    else:\n",
        "        for url in urls:\n",
        "            try:\n",
        "                r = requests.get(url, timeout=120)\n",
        "                r.raise_for_status()\n",
        "                if url.endswith(\".gz\"):\n",
        "                    with gzip.open(io.BytesIO(r.content), \"rt\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                        fill_from_rows(csv.DictReader(f))\n",
        "                else:\n",
        "                    fill_from_rows(csv.DictReader(io.StringIO(r.text)))\n",
        "                break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    source_name = \"lenta_ru\"\n",
        "\n",
        "metadatas = [{\"label\": lbl, \"source\": source_name, \"source_id\": i} for i, lbl in enumerate(labels)]\n",
        "ids = [f\"doc-{i}\" for i in range(len(texts))]\n",
        "\n",
        "print(\"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤:\", len(texts))\n",
        "print(\"–ü—Ä–∏–º–µ—Ä:\", texts[0][:200] + \"...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. RAG-–ø–∞–π–ø–ª–∞–π–Ω: —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ + Chroma + LLM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# –õ–æ–∫–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–±–µ–∑ API)\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        ")\n",
        "\n",
        "persist_dir = Path(\"./db/chroma_hw12_news\")\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"hw12_news\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=str(persist_dir),\n",
        ")\n",
        "\n",
        "vectorstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
        "if hasattr(vectorstore, \"persist\"):\n",
        "    vectorstore.persist()\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        "print(\"–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –≥–æ—Ç–æ–≤–∞\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_classic.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=500,\n",
        "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
        ")\n",
        "\n",
        "rag_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.\n",
        "\n",
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "{context}\n",
        "\n",
        "–í–æ–ø—Ä–æ—Å: {question}\n",
        "\n",
        "–û—Ç–≤–µ—Ç:\"\"\"\n",
        ")\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt},\n",
        ")\n",
        "\n",
        "def ask_rag(question: str):\n",
        "    result = rag_chain.invoke({\"query\": question})\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Langfuse: —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –û—Å–Ω–æ–≤–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ Langfuse\n",
        "\n",
        "| –°—É—â–Ω–æ—Å—Ç—å | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|----------|----------|\n",
        "| **Traces** | –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ (–≤—Å—è —Ü–µ–ø–æ—á–∫–∞) |\n",
        "| **Spans** | –û—Ç–¥–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (retrieval, pre/post processing) |\n",
        "| **Generations** | –í—ã–∑–æ–≤—ã LLM (–ø—Ä–æ–º–ø—Ç, –æ—Ç–≤–µ—Ç, —Ç–æ–∫–µ–Ω—ã, —Å—Ç–æ–∏–º–æ—Å—Ç—å) |\n",
        "| **Events** | –¢–æ—á–µ—á–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (–æ—à–∏–±–∫–∏, –∑–∞–≥—Ä—É–∑–∫–∏) |\n",
        "| **Scores** | –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (accuracy, relevance –∏ –¥—Ä.) |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langfuse import get_client\n",
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# Langfuse CallbackHandler ‚Äî –ø–µ—Ä–µ–¥–∞—ë–º –≤ LangChain –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ\")\n",
        "else:\n",
        "    print(\"Langfuse: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á–∏ LANGFUSE_SECRET_KEY, LANGFUSE_PUBLIC_KEY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –í—ã–∑–æ–≤ RAG —Å —Ç—Ä–µ–π—Å–∏–Ω–≥–æ–º ‚Äî –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (retrieval, LLM) –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ Langfuse\n",
        "question = \"–ö–∞–∫–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö?\"\n",
        "\n",
        "result = rag_chain.invoke(\n",
        "    {\"query\": question},\n",
        "    config={\"callbacks\": [langfuse_handler]},\n",
        ")\n",
        "\n",
        "print(\"–í–æ–ø—Ä–æ—Å:\", question)\n",
        "print(\"–û—Ç–≤–µ—Ç:\", result[\"result\"])\n",
        "print(\"\\n–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\", len(result.get(\"source_documents\", [])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Flush –¥–ª—è short-lived –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π (notebook) ‚Äî —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —Å–æ–±—ã—Ç–∏—è —É—à–ª–∏ –≤ Langfuse\n",
        "langfuse.flush()\n",
        "print(\"–¢—Ä–µ–π—Å—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã. –û—Ç–∫—Ä–æ–π—Ç–µ Langfuse UI: Traces ‚Üí –Ω–∞–π–¥–∏—Ç–µ trace —Å —Ç–µ–≥–æ–º hw12\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### –ß—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –ì–¥–µ —Å–º–æ—Ç—Ä–µ—Ç—å |\n",
        "|---------|--------------|\n",
        "| –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è | Trace / Span duration |\n",
        "| –í—Ö–æ–¥–Ω—ã–µ/–≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ | Input / Output –≤ –∫–∞–∂–¥–æ–º Span |\n",
        "| –¢–æ–∫–µ–Ω—ã –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å | Generation ‚Üí Usage, Cost |\n",
        "| RAG: —á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | Retrieval span ‚Üí documents count |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Langfuse Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è RAG\n",
        "DATASET_NAME = \"hw12-rag-news-eval\"\n",
        "\n",
        "try:\n",
        "    langfuse.create_dataset(name=DATASET_NAME, description=\"–¢–µ—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º –¥–ª—è RAG\")\n",
        "    print(f\"–î–∞—Ç–∞—Å–µ—Ç {DATASET_NAME} —Å–æ–∑–¥–∞–Ω\")\n",
        "except Exception as e:\n",
        "    if \"already exists\" in str(e).lower() or \"unique\" in str(e).lower():\n",
        "        print(f\"–î–∞—Ç–∞—Å–µ—Ç {DATASET_NAME} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n",
        "    else:\n",
        "        raise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã (input = –≤–æ–ø—Ä–æ—Å, expected_output = –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)\n",
        "test_items = [\n",
        "    {\"input\": {\"query\": \"–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å —ç–∫–æ–Ω–æ–º–∏–∫–æ–π?\"}, \"expected_output\": {\"keyword\": \"—ç–∫–æ–Ω–æ–º–∏–∫–∞\"}},\n",
        "    {\"input\": {\"query\": \"–ö–∞–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è?\"}, \"expected_output\": {\"keyword\": \"—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏\"}},\n",
        "    {\"input\": {\"query\": \"–ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏\"}, \"expected_output\": {\"keyword\": \"–ø–æ–ª–∏—Ç–∏–∫\"}},\n",
        "]\n",
        "\n",
        "for item in test_items:\n",
        "    langfuse.create_dataset_item(\n",
        "        dataset_name=DATASET_NAME,\n",
        "        input=item[\"input\"],\n",
        "        expected_output=item[\"expected_output\"],\n",
        "    )\n",
        "\n",
        "print(f\"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(test_items)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º evaluator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langfuse import Evaluation\n",
        "\n",
        "\n",
        "def rag_task(*, item, **kwargs):\n",
        "    \"\"\"Task –¥–ª—è experiment: –≤—ã–∑—ã–≤–∞–µ—Ç RAG –ø–æ –≤–æ–ø—Ä–æ—Å—É –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞.\"\"\"\n",
        "    query = item.input.get(\"query\", item.input) if isinstance(item.input, dict) else item.input\n",
        "    result = rag_chain.invoke(\n",
        "        {\"query\": query},\n",
        "        config={\"callbacks\": [langfuse_handler]},\n",
        "    )\n",
        "    return result[\"result\"]\n",
        "\n",
        "\n",
        "def keyword_relevance_evaluator(*, input, output, expected_output, **kwargs):\n",
        "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ –æ–∂–∏–¥–∞–µ–º–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –≤ –æ—Ç–≤–µ—Ç–µ.\"\"\"\n",
        "    keyword = expected_output.get(\"keyword\", \"\") if expected_output else \"\"\n",
        "    if not keyword:\n",
        "        return Evaluation(name=\"keyword_relevance\", value=0.5, comment=\"–ù–µ—Ç expected keyword\")\n",
        "    score = 1.0 if keyword.lower() in (output or \"\").lower() else 0.0\n",
        "    return Evaluation(\n",
        "        name=\"keyword_relevance\",\n",
        "        value=score,\n",
        "        comment=f\"Keyword '{keyword}' found: {bool(score)}\",\n",
        "    )\n",
        "\n",
        "\n",
        "def response_length_evaluator(*, output, **kwargs):\n",
        "    \"\"\"–ú–µ—Ç—Ä–∏–∫–∞: –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (RAG –¥–æ–ª–∂–µ–Ω –¥–∞–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã).\"\"\"\n",
        "    length = len(output or \"\")\n",
        "    score = min(1.0, length / 100)  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    return Evaluation(name=\"response_length\", value=length, comment=f\"–î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {length}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ Langfuse\n",
        "dataset = langfuse.get_dataset(DATASET_NAME)\n",
        "\n",
        "experiment_result = dataset.run_experiment(\n",
        "    name=\"RAG News Baseline\",\n",
        "    description=\"–ü—Ä–æ–≤–µ—Ä–∫–∞ RAG –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö\",\n",
        "    task=rag_task,\n",
        "    evaluators=[keyword_relevance_evaluator, response_length_evaluator],\n",
        ")\n",
        "\n",
        "print(experiment_result.format())\n",
        "langfuse.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "import time\n",
        "\n",
        "# –ú–µ—Ç—Ä–∏–∫–∏ –∏–∑ experiment_result\n",
        "items_list = getattr(experiment_result, \"item_results\", []) or getattr(experiment_result, \"results\", [])\n",
        "keyword_scores = []\n",
        "length_scores = []\n",
        "for item_res in items_list:\n",
        "    for ev in getattr(item_res, \"evaluations\", []):\n",
        "        if ev.name == \"keyword_relevance\":\n",
        "            keyword_scores.append(ev.value)\n",
        "        elif ev.name == \"response_length\":\n",
        "            length_scores.append(ev.value)\n",
        "\n",
        "n_items = len(items_list) or 1\n",
        "avg_keyword = sum(keyword_scores) / n_items if keyword_scores else 0\n",
        "avg_length = sum(length_scores) / n_items if length_scores else 0\n",
        "\n",
        "# –õ–æ–∫–∞–ª—å–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ (–æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å)\n",
        "_sample_q = \"–ö–∞–∫–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏?\"\n",
        "_t0 = time.perf_counter()\n",
        "_ = rag_chain.invoke({\"query\": _sample_q}, config={\"callbacks\": [langfuse_handler]})\n",
        "_latency = time.perf_counter() - _t0\n",
        "\n",
        "metrics_md = f\"\"\"\n",
        "## üìä –ú–µ—Ç—Ä–∏–∫–∏ RAG (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç + –ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–º–µ—Ä)\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |\n",
        "|---------|----------|\n",
        "| **–ö–æ–ª-–≤–æ —Ç–µ—Å—Ç–æ–≤** | {n_items} |\n",
        "| **keyword_relevance (—Å—Ä.)** | {avg_keyword:.2%} ({sum(int(s) for s in keyword_scores)}/{n_items} –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö) |\n",
        "| **response_length (—Å—Ä.)** | {avg_length:.0f} —Å–∏–º–≤–æ–ª–æ–≤ |\n",
        "| **–õ–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–ø—Ä–∏–º–µ—Ä)** | {_latency:.2f} —Å–µ–∫ |\n",
        "\n",
        "> –ü–æ–ª–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Å—Ç–æ–∏–º–æ—Å—Ç—å, —Ç–æ–∫–µ–Ω—ã) ‚Äî –≤ Langfuse UI: Experiments ‚Üí Runs\n",
        "\"\"\"\n",
        "print(metrics_md)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∞–Ω–∞–ª–∏–∑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_questions = [\n",
        "    \"–ö–∞–∫–∏–µ —Å–æ–±—ã—Ç–∏—è —Å–≤—è–∑–∞–Ω—ã —Å —ç–∫–æ–Ω–æ–º–∏–∫–æ–π?\",\n",
        "    \"–û —á—ë–º –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –Ω–æ–≤–æ—Å—Ç—è—Ö –æ –ø–æ–ª–∏—Ç–∏–∫–µ?\",\n",
        "    \"–ö–∞–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è?\",\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    r = rag_chain.invoke({\"query\": q}, config={\"callbacks\": [langfuse_handler]})\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {r['result'][:300]}...\" if len(r[\"result\"]) > 300 else f\"A: {r['result']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "langfuse.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ:** —Å–¥–µ–ª–∞–π—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –≤ Langfuse UI –∏ –æ–ø–∏—à–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
        "\n",
        "### –ß—Ç–æ –ø–æ–∫–∞–∑–∞—Ç—å:\n",
        "\n",
        "1. **Traces** ‚Äî –ø–æ–ª–Ω—ã–π trace RAG-–∑–∞–ø—Ä–æ—Å–∞ —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ spans (retrieval, generation)\n",
        "2. **Generations** ‚Äî –≤–∫–ª–∞–¥–∫–∞ —Å —Ç–æ–∫–µ–Ω–∞–º–∏ (input/output), –≤—Ä–µ–º–µ–Ω–µ–º, —Å—Ç–æ–∏–º–æ—Å—Ç—å—é\n",
        "3. **Datasets** ‚Äî –¥–∞—Ç–∞—Å–µ—Ç `hw12-rag-news-eval` –∏ –µ–≥–æ items\n",
        "4. **Experiments** ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç `RAG News Baseline` —Å scores (keyword_relevance, response_length)\n",
        "\n",
        "### –ü—Ä–∏–º–µ—Ä –æ–ø–∏—Å–∞–Ω–∏—è:\n",
        "\n",
        "```markdown\n",
        "## –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –î–ó 12\n",
        "\n",
        "### –ú–µ—Ç—Ä–∏–∫–∏ –∏–∑ Langfuse\n",
        "- –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: X —Å–µ–∫\n",
        "- –¢–æ–∫–µ–Ω—ã (–≤—Ö–æ–¥/–≤—ã—Ö–æ–¥): ~Y / ~Z\n",
        "- –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ –∑–∞–ø—Ä–æ—Å: ~$0.00X\n",
        "- keyword_relevance (experiment): N/N = X%\n",
        "\n",
        "### –°–∫—Ä–∏–Ω—à–æ—Ç—ã\n",
        "- [Trace RAG](screenshots/trace_rag.png)\n",
        "- [Experiment scores](screenshots/experiment_scores.png)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–ª—è short-lived –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
        "langfuse.flush()\n",
        "print(\"–ì–æ—Ç–æ–≤–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Langfuse UI –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö traces –∏ experiment —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}